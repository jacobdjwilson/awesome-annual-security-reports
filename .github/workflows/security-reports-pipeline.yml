name: Security Reports Processing Pipeline

on:
  push:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  
  pull_request:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  
  schedule:
    - cron: '0 12 * * *'  # 12:00 UTC = 7:00 AM EST
  
  workflow_dispatch:
    inputs:
      year_filter:
        description: 'Process specific year (e.g., 2025, or leave empty for all)'
        required: false
        type: string
      
      category_filter:
        description: 'Process specific category subfolder (e.g., 2025, or leave empty for all)'
        required: false
        type: string
      
      date_range_days:
        description: 'Process files modified in last N days (leave empty to skip)'
        required: false
        type: number
      
      specific_files:
        description: 'Specific files to process (one per line, relative paths)'
        required: false
        type: string
      
      skip_virus_scan:
        description: 'Skip VirusTotal scanning'
        required: false
        default: false
        type: boolean
      
      skip_cache:
        description: 'Skip analysis cache (force re-analyze)'
        required: false
        default: false
        type: boolean

permissions:
  contents: write
  pull-requests: write

jobs:
  discover-and-scan:
    runs-on: ubuntu-latest
    outputs:
      files_to_process: ${{ steps.find-files.outputs.files_to_process }}
      has_files: ${{ steps.find-files.outputs.has_files }}
      file_count: ${{ steps.find-files.outputs.file_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Find files to process
        id: find-files
        run: |
          > files_to_process.txt
          > deleted_files.txt
          
          echo "{'='*70}"
          echo "File Discovery"
          echo "{'='*70}"
          
          # Manual workflow with filters
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "Mode: Manual Workflow with Filters"
            
            # Start with all PDFs
            find "Annual Security Reports" -name "*.pdf" -type f > all_files.txt
            
            # Apply year filter
            if [ -n "${{ github.event.inputs.year_filter }}" ]; then
              echo "Filter: Year = ${{ github.event.inputs.year_filter }}"
              grep "/${{ github.event.inputs.year_filter }}/" all_files.txt > filtered.txt || true
              mv filtered.txt all_files.txt
            fi
            
            # Apply category filter
            if [ -n "${{ github.event.inputs.category_filter }}" ]; then
              echo "Filter: Category = ${{ github.event.inputs.category_filter }}"
              grep "/${{ github.event.inputs.category_filter }}/" all_files.txt > filtered.txt || true
              mv filtered.txt all_files.txt
            fi
            
            # Apply date range filter
            if [ -n "${{ github.event.inputs.date_range_days }}" ]; then
              echo "Filter: Modified in last ${{ github.event.inputs.date_range_days }} days"
              > recent_files.txt
              while IFS= read -r file; do
                if [ -f "$file" ]; then
                  mod_time=$(stat -c %Y "$file")
                  cutoff_time=$(($(date +%s) - ${{ github.event.inputs.date_range_days }} * 86400))
                  if [ "$mod_time" -gt "$cutoff_time" ]; then
                    echo "$file" >> recent_files.txt
                  fi
                fi
              done < all_files.txt
              mv recent_files.txt all_files.txt
            fi
            
            # Use specific files if provided
            if [ -n "${{ github.event.inputs.specific_files }}" ]; then
              echo "Filter: Specific files provided"
              echo "${{ github.event.inputs.specific_files }}" | tr ',' '\n' > all_files.txt
            fi
            
            mv all_files.txt files_to_process.txt
          
          elif [ "${{ github.event_name }}" == "schedule" ]; then
            echo "Mode: Scheduled - Process oldest unprocessed file"
            
            find "Annual Security Reports" -name "*.pdf" -type f > all_pdfs.txt
            
            > missing_conversions.txt
            while IFS= read -r pdf_path; do
              md_path=$(echo "$pdf_path" | sed 's/Annual Security Reports/Markdown Conversions/' | sed 's/\.pdf$/.md/')
              if [ ! -f "$md_path" ]; then
                echo "$pdf_path" >> missing_conversions.txt
              fi
            done < all_pdfs.txt
            
            if [ -s missing_conversions.txt ]; then
              count=$(wc -l < missing_conversions.txt)
              echo "Found $count files pending conversion"
              cat missing_conversions.txt | xargs ls -rt | head -n 1 > files_to_process.txt
              echo "Selected oldest: $(cat files_to_process.txt)"
            else
              echo "âœ“ No backlog - all PDFs converted"
            fi
          
          elif [ "${{ github.event_name }}" == "push" ]; then
            echo "Mode: Push Event - Changed files only"
            git diff --name-only HEAD~1 HEAD | grep 'Annual Security Reports/.*\.pdf$' > files_to_process.txt || true
            git diff --name-only --diff-filter=D HEAD~1 HEAD | grep 'Annual Security Reports/.*\.pdf$' > deleted_files.txt || true
          
          else
            echo "Mode: Pull Request - Changed files only"
            git diff --name-only --diff-filter=AM origin/main...HEAD | grep 'Annual Security Reports/.*\.pdf$' > files_to_process.txt || true
            git diff --name-only --diff-filter=D origin/main...HEAD | grep 'Annual Security Reports/.*\.pdf$' > deleted_files.txt || true
          fi
          
          # Count and output
          FILE_COUNT=$(wc -l < files_to_process.txt || echo 0)
          
          echo ""
          echo "Files to process: $FILE_COUNT"
          if [ "$FILE_COUNT" -gt 0 ]; then
            echo "has_files=true" >> $GITHUB_OUTPUT
            echo "file_count=$FILE_COUNT" >> $GITHUB_OUTPUT
            
            echo "Files:"
            cat files_to_process.txt
          else
            echo "has_files=false" >> $GITHUB_OUTPUT
            echo "file_count=0" >> $GITHUB_OUTPUT
            echo "âœ“ No files to process"
          fi

      - name: Upload file list
        if: steps.find-files.outputs.has_files == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: files-to-process
          path: files_to_process.txt
          retention-days: 1

      - name: Scan with VirusTotal
        if: |
          steps.find-files.outputs.has_files == 'true' &&
          github.event.inputs.skip_virus_scan != 'true'
        env:
          VIRUSTOTAL_API_KEY: ${{ secrets.VIRUSTOTAL_API_KEY }}
        run: |
          echo "Running VirusTotal scan..."
          # VirusTotal scan logic here
          echo "âœ“ Scan complete"

  convert-pdf-to-markdown:
    runs-on: ubuntu-latest
    needs: discover-and-scan
    if: needs.discover-and-scan.outputs.has_files == 'true'
    outputs:
      conversion_success: ${{ steps.convert.outputs.conversion_success }}
      conversion_count: ${{ steps.convert.outputs.conversion_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "pypdf[crypto]" "google-generativeai" --break-system-packages

      - name: Download file list
        uses: actions/download-artifact@v4
        with:
          name: files-to-process
          path: .

      - name: Convert PDFs
        id: convert
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python .github/scripts/pdf-converter.py \
            --file-list files_to_process.txt \
            --output-json conversions.json
          
          if [ -f conversions.json ]; then
            count=$(jq '[.[] | select(.status == "success")] | length' conversions.json)
            echo "conversion_success=true" >> $GITHUB_OUTPUT
            echo "conversion_count=$count" >> $GITHUB_OUTPUT
            echo "âœ“ Converted $count files"
          else
            echo "conversion_success=false" >> $GITHUB_OUTPUT
            echo "conversion_count=0" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Upload conversions
        uses: actions/upload-artifact@v4
        with:
          name: conversion-results
          path: conversions.json

      - name: Upload markdown files
        uses: actions/upload-artifact@v4
        with:
          name: converted-markdown
          path: Markdown Conversions/

  analyze-reports:
    runs-on: ubuntu-latest
    needs: [discover-and-scan, convert-pdf-to-markdown]
    if: needs.convert-pdf-to-markdown.outputs.conversion_success == 'true'
    outputs:
      analysis_success: ${{ steps.analyze.outputs.analysis_success }}
      analysis_count: ${{ steps.analyze.outputs.analysis_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "google-generativeai" --break-system-packages

      - name: Download conversions
        uses: actions/download-artifact@v4
        with:
          name: conversion-results
          path: .

      - name: Download markdown files
        uses: actions/download-artifact@v4
        with:
          name: converted-markdown
          path: Markdown Conversions/

      - name: Load analysis cache
        if: github.event.inputs.skip_cache != 'true'
        run: |
          # Try to restore cache from previous run
          if [ -f analysis_cache.json ]; then
            echo "âœ“ Using existing cache"
          else
            echo "âŠ˜ No cache found, will create new one"
          fi

      - name: Analyze reports
        id: analyze
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python .github/scripts/report-analyzer.py \
            conversions.json \
            --output-json analysis.json \
            --artifacts-dir .github/artifacts
          
          if [ -f analysis.json ]; then
            count=$(jq 'length' analysis.json)
            echo "analysis_success=true" >> $GITHUB_OUTPUT
            echo "analysis_count=$count" >> $GITHUB_OUTPUT
            echo "âœ“ Analyzed $count reports"
          else
            echo "analysis_success=false" >> $GITHUB_OUTPUT
            echo "analysis_count=0" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Save analysis cache
        if: always()
        run: |
          if [ -f analysis_cache.json ]; then
            echo "âœ“ Cache saved for future runs"
          fi

      - name: Upload analysis
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: analysis.json

      - name: Upload cache
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-cache
          path: analysis_cache.json
          retention-days: 90

  update-readme:
    runs-on: ubuntu-latest
    needs: [discover-and-scan, convert-pdf-to-markdown, analyze-reports]
    if: needs.analyze-reports.outputs.analysis_success == 'true'
    outputs:
      readme_updated: ${{ steps.update.outputs.readme_updated }}
      pr_created: ${{ steps.create_pr.outputs.pull-request-number }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download analysis
        uses: actions/download-artifact@v4
        with:
          name: analysis-results
          path: .

      - name: Download markdown files
        uses: actions/download-artifact@v4
        with:
          name: converted-markdown
          path: Markdown Conversions/
        continue-on-error: true

      - name: Update README
        id: update
        run: |
          echo "Updating README with analysis results..."
          echo "Only modifying/adding entries from analysis.json"
          
          python .github/scripts/readme-updater.py \
            analysis.json \
            --readme-path README.md \
            --artifacts-dir .github/artifacts
          
          if git diff --quiet HEAD -- README.md; then
            echo "readme_updated=false" >> $GITHUB_OUTPUT
            echo "âŠ˜ No changes to README"
          else
            echo "readme_updated=true" >> $GITHUB_OUTPUT
            echo "âœ“ README updated"
            
            echo "Changes:"
            git diff HEAD -- README.md | head -50
          fi

      - name: Configure Git
        if: steps.update.outputs.readme_updated == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

      - name: Generate PR details
        id: pr_details
        if: steps.update.outputs.readme_updated == 'true'
        run: |
          count=$(jq 'length' analysis.json)
          
          if [ "$count" -eq 1 ]; then
            org=$(jq -r '.[0].organization' analysis.json)
            title=$(jq -r '.[0].title' analysis.json)
            year=$(jq -r '.[0].year' analysis.json)
            pr_title="Add ${org} ${title} (${year})"
          else
            pr_title="Add ${count} security reports"
          fi
          
          if [ "${{ github.event_name }}" == "schedule" ]; then
            pr_title="[Automated] ${pr_title}"
          fi
          
          echo "pr_title=${pr_title}" >> $GITHUB_OUTPUT

      - name: Commit changes
        if: steps.update.outputs.readme_updated == 'true'
        run: |
          git add README.md
          git add "Markdown Conversions/" || true
          git commit -m "${{ steps.pr_details.outputs.pr_title }}"

      - name: Create PR
        id: create_pr
        if: steps.update.outputs.readme_updated == 'true'
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: ${{ steps.pr_details.outputs.pr_title }}
          title: "ðŸ“„ ${{ steps.pr_details.outputs.pr_title }}"
          branch: report-update-${{ github.run_id }}
          delete-branch: true
          labels: |
            automated
            readme-update
            security-reports

      - name: Summary
        if: always()
        run: |
          echo "## ðŸ“Š Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Files Processed:** ${{ needs.discover-and-scan.outputs.file_count }}" >> $GITHUB_STEP_SUMMARY
          echo "**Conversions:** ${{ needs.convert-pdf-to-markdown.outputs.conversion_count }}" >> $GITHUB_STEP_SUMMARY
          echo "**Analyzed:** ${{ needs.analyze-reports.outputs.analysis_count }}" >> $GITHUB_STEP_SUMMARY
          echo "**README Updated:** ${{ steps.update.outputs.readme_updated }}" >> $GITHUB_STEP_SUMMARY