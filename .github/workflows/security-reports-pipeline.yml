name: Security Reports Processing Pipeline

on:
  push:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  pull_request:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  workflow_dispatch:
    inputs:
      force_scan_all:
        description: 'Force scan all PDF files (not just changed)'
        required: false
        default: 'false'
        type: boolean
      skip_virus_scan:
        description: 'Skip VirusTotal scanning'
        required: false
        default: 'false'
        type: boolean

permissions:
  contents: write
  pull-requests: write

jobs:
  discover-and-scan:
    runs-on: ubuntu-latest
    outputs:
      files_to_process: ${{ steps.find-files.outputs.files_to_process }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Find changed PDF files
        id: find-files
        run: |
          if [[ "${{ github.event.inputs.force_scan_all }}" == "true" ]]; then
            find "Annual Security Reports" -name "*.pdf" > files_to_process.txt
            touch deleted_files.txt
          else
            git diff --name-only --diff-filter=AM ${{ github.event.before }} ${{ github.event.after }} | grep 'Annual Security Reports/.*\.pdf$' > files_to_process.txt || true
            git diff --name-only --diff-filter=D ${{ github.event.before }} ${{ github.event.after }} | grep 'Annual Security Reports/.*\.pdf$' > deleted_files.txt || true
          fi
          
          echo "--- Content of files_to_process.txt ---"
          cat -v files_to_process.txt
          echo "--- End of files_to_process.txt ---"

          # Convert files_to_process.txt to a JSON array and set as output
          if [ -s files_to_process.txt ]; then
            # Read each line, trim whitespace, and filter out empty lines
            files_content=$(cat files_to_process.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' | grep -v '^$')
            
            # Initialize JSON array
            json_array="["
            first_item=true
            
            # Loop through each file path
            while IFS= read -r line; do
              # Remove any trailing commas that might have been introduced somehow
              line=$(echo "$line" | sed 's/,$//')
              if [ "$first_item" = false ]; then
                json_array+=,
              fi
              json_array+="\"$line\""
              first_item=false
            done <<< "$files_content"
            
            json_array+="]"
            
            echo "--- Content of json_array variable ---"
            echo "$json_array"
            echo "--- End of json_array variable ---"

            echo "files_to_process<<EOF" >> $GITHUB_OUTPUT
            echo "$json_array" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            echo "files_to_process=[]" >> $GITHUB_OUTPUT
          fi

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Setup Python Environment
        if: steps.find-files.outputs.files_to_process != ''
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        if: steps.find-files.outputs.files_to_process != ''
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Run VirusTotal Scan
        if: steps.find-files.outputs.files_to_process != '' && github.event.inputs.skip_virus_scan != 'true'
        env:
          VIRUS_TOTAL_API_KEY: ${{ secrets.VIRUS_TOTAL_API_KEY }}
        run: |
          python .github/scripts/virus-total-scan.py files_to_process.txt --deleted-files deleted_files.txt --output-json scan_results.json

      - name: Upload scan results
        if: steps.find-files.outputs.files_to_process != ''
        uses: actions/upload-artifact@v4
        with:
          name: scan-results
          path: scan_results.json

      - name: Upload files to process
        if: steps.find-files.outputs.files_to_process != ''
        uses: actions/upload-artifact@v4
        with:
          name: files-to-process
          path: files_to_process.txt

      - name: Upload deleted files list
        if: steps.find-files.outputs.files_to_process != ''
        uses: actions/upload-artifact@v4
        with:
          name: deleted-files
          path: deleted_files.txt

  process-and-analyze-report:
    runs-on: ubuntu-latest
    needs: discover-and-scan
    if: needs.discover-and-scan.outputs.files_to_process != '[]'
    strategy:
      matrix:
        pdf_file: ${{ fromJson(needs.discover-and-scan.outputs.files_to_process) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install markitdown[pdf] google-generativeai google-api-python-client

      - name: Run PDF Converter
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GOOGLE_SEARCH_API_KEY: ${{ secrets.GOOGLE_SEARCH_API_KEY }}
          GOOGLE_CSE_ID: ${{ secrets.GOOGLE_CSE_ID }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          PDF_FILE="${{ matrix.pdf_file }}"
          PROMPT_PATH=".github/ai-prompts/pdf-to-markdown-prompt.md"
          PROMPT_VERSION=$(git log -n 1 --pretty=format:%s -- $PROMPT_PATH | grep -oP 'v\d+\.\d+(\.\d+)?' || echo 'v1.0')
          BRANCH_NAME=${{ github.head_ref || github.ref_name }}
          
          # Create a temporary file for the single PDF path
          echo "$PDF_FILE" > single_pdf_file.txt
          
          python .github/scripts/pdf-converter.py single_pdf_file.txt $PROMPT_PATH $PROMPT_VERSION $BRANCH_NAME --output-json conversions.json

      

      - name: Run Report Analyzer
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python .github/scripts/report-analyzer.py conversions.json --readme-path README.md --output-json analysis.json

      - name: Upload analysis results
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results-${{ hashFiles(matrix.pdf_file) }}
          path: analysis.json

  update-readme:
    runs-on: ubuntu-latest
    needs: process-and-analyze-report
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull latest changes
        run: git pull

      - name: Download all analysis results
        uses: actions/download-artifact@v4
        with:
          name: analysis-results-*
          path: analysis-artifacts

      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-generativeai

      - name: Combine analysis results
        id: combine_analysis
        run: |
          mkdir -p combined_analysis
          echo "[]" > combined_analysis/all_analysis.json
          for dir in analysis-artifacts/*/; 
            if [ -f "$dir/analysis.json" ]; then
              jq --argfile existing combined_analysis/all_analysis.json '. + $existing' "$dir/analysis.json" > temp.json && mv temp.json combined_analysis/all_analysis.json
            fi
          done
          
          # Check if the combined file is empty or contains only an empty array
          if [ ! -s combined_analysis/all_analysis.json ] || [ "$(cat combined_analysis/all_analysis.json)" = "[]" ]; then
            echo "combined_analysis_exists=false" >> $GITHUB_OUTPUT
          else
            echo "combined_analysis_exists=true" >> $GITHUB_OUTPUT
          fi

      - name: Run README Updater
        if: steps.combine_analysis.outputs.combined_analysis_exists == 'true'
        run: |
          python .github/scripts/readme-updater.py combined_analysis/all_analysis.json --readme-path README.md

      - name: Commit and Push Changes
        if: steps.combine_analysis.outputs.combined_analysis_exists == 'true'
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add README.md
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Update README with latest security reports"
            git push
          fi

  push-changes:
    runs-on: ubuntu-latest
    needs: [process-and-analyze-report, update-readme]
    if: always() && (needs.process-and-analyze-report.result == 'success' || needs.update-readme.result == 'success')
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0 # Fetch all history for git operations

      - name: Push all changes
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git pull --rebase # Rebase to avoid conflicts
          git push

  - name: Commit and Push Changes
        if: steps.combine_analysis.outputs.combined_analysis_exists == 'true'
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add README.md
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Update README with latest security reports"
            git push
          fi