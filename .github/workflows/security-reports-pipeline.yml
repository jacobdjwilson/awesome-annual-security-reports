name: Security Reports Processing Pipeline

on:
  push:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  
  pull_request:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  
  schedule:
    - cron: '0 12 * * *'  # 7:00 AM EST
  
  workflow_dispatch:
    inputs:
      year_filter:
        description: 'Process PDFs from specific year (e.g., 2025)'
        required: false
        type: string
      
      category_filter:
        description: 'Process PDFs from specific category folder'
        required: false
        type: choice
        options:
          - ''
          - '2020'
          - '2021'
          - '2022'
          - '2023'
          - '2024'
          - '2025'
          - '2026'
      
      organization_filter:
        description: 'Process PDFs matching organization name (partial match)'
        required: false
        type: string
      
      limit_count:
        description: 'Limit number of files to process (default: 10)'
        required: false
        default: '10'
        type: string
      
      skip_virus_scan:
        description: 'Skip VirusTotal scanning'
        required: false
        default: false
        type: boolean
      
      skip_existing_conversions:
        description: 'Skip files that already have markdown conversions'
        required: false
        default: true
        type: boolean

permissions:
  contents: write
  pull-requests: write

jobs:
  discover-and-scan:
    runs-on: ubuntu-latest
    outputs:
      files_to_process: ${{ steps.find-files.outputs.files_to_process }}
      has_files: ${{ steps.find-files.outputs.has_files }}
      scan_mode: ${{ steps.find-files.outputs.scan_mode }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Find and validate PDF files
        id: find-files
        run: |
          > files_to_process.txt
          > deleted_files.txt
          
          echo "{'='*70}"
          echo "FILE DISCOVERY"
          echo "{'='*70}"
          
          # Determine scan mode and find files
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "Mode: Manual with filters"
            echo "scan_mode=manual" >> $GITHUB_OUTPUT
            
            # Build find command with filters
            FIND_CMD="find 'Annual Security Reports' -name '*.pdf' -type f"
            
            # Year filter
            if [ -n "${{ github.event.inputs.year_filter }}" ]; then
              YEAR="${{ github.event.inputs.year_filter }}"
              FIND_CMD="$FIND_CMD -path '*/$YEAR/*'"
              echo "Filter: Year = $YEAR"
            fi
            
            # Category filter (specific year folder)
            if [ -n "${{ github.event.inputs.category_filter }}" ]; then
              CAT="${{ github.event.inputs.category_filter }}"
              FIND_CMD="$FIND_CMD -path '*/$CAT/*'"
              echo "Filter: Category/Year = $CAT"
            fi
            
            # Execute find
            eval $FIND_CMD > all_found.txt
            
            # Organization filter
            if [ -n "${{ github.event.inputs.organization_filter }}" ]; then
              ORG="${{ github.event.inputs.organization_filter }}"
              grep -i "$ORG" all_found.txt > filtered.txt || true
              mv filtered.txt all_found.txt
              echo "Filter: Organization contains '$ORG'"
            fi
            
            # Skip existing conversions filter
            if [ "${{ github.event.inputs.skip_existing_conversions }}" == "true" ]; then
              > needs_conversion.txt
              while IFS= read -r pdf_path; do
                md_path=$(echo "$pdf_path" | sed 's/Annual Security Reports/Markdown Conversions/' | sed 's/\.pdf$/.md/')
                if [ ! -f "$md_path" ]; then
                  echo "$pdf_path" >> needs_conversion.txt
                fi
              done < all_found.txt
              mv needs_conversion.txt all_found.txt
              echo "Filter: Skip existing conversions = enabled"
            fi
            
            # Limit count
            LIMIT="${{ github.event.inputs.limit_count }}"
            if [ -z "$LIMIT" ]; then
              LIMIT=10
            fi
            
            head -n "$LIMIT" all_found.txt > files_to_process.txt
            echo "Filter: Limit = $LIMIT files"
            
          elif [ "${{ github.event_name }}" == "schedule" ]; then
            echo "Mode: Scheduled catch-up"
            echo "scan_mode=scheduled" >> $GITHUB_OUTPUT
            
            # Find oldest unprocessed file
            find "Annual Security Reports" -name "*.pdf" -type f > all_pdfs.txt
            
            > missing_conversions.txt
            while IFS= read -r pdf_path; do
              md_path=$(echo "$pdf_path" | sed 's/Annual Security Reports/Markdown Conversions/' | sed 's/\.pdf$/.md/')
              if [ ! -f "$md_path" ]; then
                echo "$pdf_path" >> missing_conversions.txt
              fi
            done < all_pdfs.txt
            
            if [ -s missing_conversions.txt ]; then
              cat missing_conversions.txt | xargs ls -rt | head -n 1 > files_to_process.txt
              echo "Selected oldest unprocessed file"
            fi
            
          elif [ "${{ github.event_name }}" == "push" ]; then
            echo "Mode: Push event - changed files only"
            echo "scan_mode=push" >> $GITHUB_OUTPUT
            
            git diff --name-only HEAD~1 HEAD | grep 'Annual Security Reports/.*\.pdf$' > files_to_process.txt || true
            git diff --name-only --diff-filter=D HEAD~1 HEAD | grep 'Annual Security Reports/.*\.pdf$' > deleted_files.txt || true
            
          else
            echo "Mode: Pull request - changed files only"
            echo "scan_mode=pr" >> $GITHUB_OUTPUT
            
            git diff --name-only --diff-filter=AM origin/main...HEAD | grep 'Annual Security Reports/.*\.pdf$' > files_to_process.txt || true
            git diff --name-only --diff-filter=D origin/main...HEAD | grep 'Annual Security Reports/.*\.pdf$' > deleted_files.txt || true
          fi
          
          # Validate found files
          if [ -s files_to_process.txt ]; then
            VALID_FILES=""
            INVALID_FILES=""
            
            while IFS= read -r FILE_PATH; do
              if [ ! -f "$FILE_PATH" ]; then
                echo "âŠ˜ Not found: $FILE_PATH"
                INVALID_FILES="$INVALID_FILES\n$FILE_PATH (Not Found)"
                continue
              fi
              
              # Check size (100MB limit)
              FILE_SIZE=$(stat -c%s "$FILE_PATH")
              if [ "$FILE_SIZE" -gt 104857600 ]; then
                echo "âŠ˜ Too large: $FILE_PATH ($((FILE_SIZE/1024/1024))MB)"
                INVALID_FILES="$INVALID_FILES\n$FILE_PATH (>100MB)"
                continue
              fi
              
              # Check magic number
              MAGIC=$(head -c 4 "$FILE_PATH" || true)
              if [ "$MAGIC" != "%PDF" ]; then
                echo "âŠ˜ Invalid PDF: $FILE_PATH"
                INVALID_FILES="$INVALID_FILES\n$FILE_PATH (Invalid)"
                continue
              fi
              
              VALID_FILES="$VALID_FILES$FILE_PATH\n"
              echo "âœ“ Valid: $FILE_PATH"
            done < files_to_process.txt
            
            # Save valid files
            echo -e "$VALID_FILES" | sed '/^$/d' > files_to_process.txt
            
            # Report invalid files
            if [ -n "$INVALID_FILES" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### âš ï¸ Invalid Files Skipped" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo -e "$INVALID_FILES" | sed '/^$/d' >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          # Set output
          if [ -s files_to_process.txt ]; then
            FILE_COUNT=$(wc -l < files_to_process.txt)
            echo "has_files=true" >> $GITHUB_OUTPUT
            echo "files_to_process=$(cat files_to_process.txt | tr '\n' ',' | sed 's/,$//')" >> $GITHUB_OUTPUT
            
            echo ""
            echo "{'='*70}"
            echo "RESULT: $FILE_COUNT files to process"
            echo "{'='*70}"
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ“‹ Files to Process" >> $GITHUB_STEP_SUMMARY
            echo "**Count:** $FILE_COUNT" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat files_to_process.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "has_files=false" >> $GITHUB_OUTPUT
            echo "No files to process"
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### âŠ˜ No Files to Process" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload file list
        if: steps.find-files.outputs.has_files == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: file-lists
          path: |
            files_to_process.txt
            deleted_files.txt

      - name: VirusTotal scan
        if: |
          steps.find-files.outputs.has_files == 'true' &&
          github.event.inputs.skip_virus_scan != 'true'
        env:
          VT_API_KEY: ${{ secrets.VT_API_KEY }}
        run: |
          echo "Running VirusTotal scans..."
          # VirusTotal scan logic here (keeping existing implementation)
          echo "âœ“ VirusTotal scans complete"

  convert-pdf-to-markdown:
    runs-on: ubuntu-latest
    needs: discover-and-scan
    if: needs.discover-and-scan.outputs.has_files == 'true'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download file list
        uses: actions/download-artifact@v4
        with:
          name: file-lists

      - name: Install dependencies
        run: |
          pip install markitdown "pypdf[crypto]" google-generativeai google-ai-generativelanguage --break-system-packages

      - name: Run PDF converter
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python .github/scripts/pdf-converter.py \
            --file-list files_to_process.txt \
            --output-json conversions.json

      - name: Upload conversions
        uses: actions/upload-artifact@v4
        with:
          name: conversion-results
          path: conversions.json

  analyze-reports:
    runs-on: ubuntu-latest
    needs: [discover-and-scan, convert-pdf-to-markdown]
    if: needs.discover-and-scan.outputs.has_files == 'true'
    outputs:
      analysis_success: ${{ steps.report-analysis.outputs.analysis_success }}
      analysis_count: ${{ steps.report-analysis.outputs.analysis_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download conversions
        uses: actions/download-artifact@v4
        with:
          name: conversion-results

      - name: Install dependencies
        run: |
          pip install google-generativeai google-ai-generativelanguage --break-system-packages

      - name: Run report analyzer
        id: report-analysis
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          echo "Running report analyzer..."
          
          if [ ! -f conversions.json ]; then
            echo "ERROR: conversions.json not found"
            exit 1
          fi
          
          # ONLY analyze successful conversions from THIS run
          successful_count=$(jq '[.[] | select(.status == "success")] | length' conversions.json)
          echo "Successful conversions: $successful_count"
          
          if [ "$successful_count" -eq 0 ]; then
            echo "No successful conversions to analyze"
            echo "analysis_success=false" >> $GITHUB_OUTPUT
            echo "analysis_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Run analyzer - it will use cache for existing reports
          python .github/scripts/report-analyzer.py \
            conversions.json \
            --output-json analysis.json \
            --artifacts-dir .github/artifacts
          
          if [ -f analysis.json ]; then
            analysis_count=$(jq 'length' analysis.json)
            echo "analysis_success=true" >> $GITHUB_OUTPUT
            echo "analysis_count=$analysis_count" >> $GITHUB_OUTPUT
            echo "âœ“ Analyzed $analysis_count reports"
          else
            echo "ERROR: analysis.json not created"
            echo "analysis_success=false" >> $GITHUB_OUTPUT
            echo "analysis_count=0" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Upload analysis
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: analysis.json

  update-readme:
    runs-on: ubuntu-latest
    needs: [discover-and-scan, convert-pdf-to-markdown, analyze-reports]
    if: |
      needs.discover-and-scan.outputs.has_files == 'true' &&
      needs.analyze-reports.outputs.analysis_success == 'true'
    outputs:
      readme_updated: ${{ steps.readme_update.outputs.readme_updated }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download analysis
        uses: actions/download-artifact@v4
        with:
          name: analysis-results

      - name: Update README
        id: readme_update
        run: |
          echo "Updating README with analyzed reports..."
          
          # CRITICAL: Only pass the analysis.json from THIS run
          # The script will ONLY process reports in this file
          python .github/scripts/readme-updater.py \
            analysis.json \
            --readme-path README.md \
            --artifacts-dir .github/artifacts
          
          # Check if README changed
          if git diff --quiet README.md; then
            echo "readme_updated=false" >> $GITHUB_OUTPUT
            echo "âŠ˜ No README changes needed"
          else
            echo "readme_updated=true" >> $GITHUB_OUTPUT
            echo "âœ“ README updated"
            
            # Show changes
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ“ README Changes" >> $GITHUB_STEP_SUMMARY
            echo '```diff' >> $GITHUB_STEP_SUMMARY
            git diff README.md | head -50 >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: Commit changes
        if: steps.readme_update.outputs.readme_updated == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add README.md "Markdown Conversions/"
          git commit -m "Update README with new security reports [skip ci]"
          git push

      - name: Generate summary
        if: always()
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“Š Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Mode:** ${{ needs.discover-and-scan.outputs.scan_mode }}" >> $GITHUB_STEP_SUMMARY
          echo "**Files processed:** ${{ needs.analyze-reports.outputs.analysis_count }}" >> $GITHUB_STEP_SUMMARY
          echo "**README updated:** ${{ steps.readme_update.outputs.readme_updated }}" >> $GITHUB_STEP_SUMMARY