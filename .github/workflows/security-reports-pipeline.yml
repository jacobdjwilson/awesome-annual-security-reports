name: Security Reports Processing Pipeline

on:
  push:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  pull_request:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  workflow_dispatch:
    inputs:
      force_scan_all:
        description: 'Force scan all PDF files (not just changed)'
        required: false
        default: 'false'
        type: boolean
      skip_virus_scan:
        description: 'Skip VirusTotal scanning'
        required: false
        default: 'false'
        type: boolean

permissions:
  contents: write
  pull-requests: write

jobs:
  discover-and-scan:
    runs-on: ubuntu-latest
    outputs:
      files_to_process: ${{ steps.find-files.outputs.files_to_process }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Find changed PDF files
        id: find-files
        run: |
          if [[ "${{ github.event.inputs.force_scan_all }}" == "true" ]]; then
            find "Annual Security Reports" -name "*.pdf" > files_to_process.txt
            touch deleted_files.txt
          else
            git diff --name-only --diff-filter=AM ${{ github.event.before }} ${{ github.event.after }} | grep 'Annual Security Reports/.*\.pdf$' > files_to_process.txt || true
            git diff --name-only --diff-filter=D ${{ github.event.before }} ${{ github.event.after }} | grep 'Annual Security Reports/.*\.pdf$' > deleted_files.txt || true
          fi
          
          echo "--- Content of files_to_process.txt ---"
          cat -v files_to_process.txt
          echo "--- End of files_to_process.txt ---"

          # Convert files_to_process.txt to a JSON array and set as output
          if [ -s files_to_process.txt ]; then
            # Read each line, trim whitespace, and filter out empty lines
            files_content=$(cat files_to_process.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' | grep -v '^$')
            
            # Initialize JSON array
            json_array="["
            first_item=true
            
            # Loop through each file path
            while IFS= read -r line; do
              # Remove any trailing commas that might have been introduced somehow
              line=$(echo "$line" | sed 's/,$//')
              if [ "$first_item" = false ]; then
                json_array+=,
              fi
              json_array+="\"$line\""
              first_item=false
            done <<< "$files_content"
            
            json_array+="]"
            
            echo "--- Content of json_array variable ---"
            echo "$json_array"
            echo "--- End of json_array variable ---"

            echo "files_to_process<<EOF" >> $GITHUB_OUTPUT
            echo "$json_array" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            echo "files_to_process=[]" >> $GITHUB_OUTPUT
          fi

      - name: Generate Discovery Summary
        id: discovery-summary
        run: |
          echo "### Discovery Scan Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### Report Counts" >> $GITHUB_STEP_SUMMARY
          echo "| Directory | PDF Reports | Markdown Conversions |
|---|---|---|" >> $GITHUB_STEP_SUMMARY
          for year_dir in Annual\ Security\ Reports/*/; do
            year=$(basename "$year_dir")
            pdf_count=$(find "$year_dir" -name "*.pdf" -type f | wc -l)
            md_count=$(find "Markdown Conversions/$year" -name "*.md" -type f | wc -l)
            echo "| $year | $pdf_count | $md_count |" >> $GITHUB_STEP_SUMMARY
          done
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### New/Modified Files Found" >> $GITHUB_STEP_SUMMARY
          if [ -s files_to_process.txt ]; then
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat files_to_process.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "No new or modified PDF files found." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Setup Python Environment
        if: steps.find-files.outputs.files_to_process != '[]'
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        if: steps.find-files.outputs.files_to_process != '[]'
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Run VirusTotal Scan
        if: steps.find-files.outputs.files_to_process != '[]' && github.event.inputs.skip_virus_scan != 'true'
        env:
          VIRUS_TOTAL_API_KEY: ${{ secrets.VIRUS_TOTAL_API_KEY }}
        run: |
          python .github/scripts/virus-total-scan.py files_to_process.txt --deleted-files deleted_files.txt --output-json scan_results.json

      - name: Generate VirusTotal Scan Summary
        if: steps.find-files.outputs.files_to_process != '[]' && github.event.inputs.skip_virus_scan != 'true'
        run: |
          echo "### VirusTotal Security Scan Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f scan_results.json ]; then
            echo "| File | Status | Details |
|---|---|---|" >> $GITHUB_STEP_SUMMARY
            # This assumes scan_results.json is an array of objects with file_path, status, and details keys.
            # You may need to adjust the jq query based on the actual structure of scan_results.json.
            jq -r '.[] | "| `\(.file_path)` | \(.status) | \(.details // "N/A") |"' scan_results.json >> $GITHUB_STEP_SUMMARY
          else
            echo "Scan results file not found or scan was skipped." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload scan results
        if: steps.find-files.outputs.files_to_process != '[]'
        uses: actions/upload-artifact@v4
        with:
          name: scan-results
          path: scan_results.json

      - name: Upload files to process
        if: steps.find-files.outputs.files_to_process != '[]'
        uses: actions/upload-artifact@v4
        with:
          name: files-to-process
          path: files_to_process.txt

      - name: Upload deleted files list
        if: steps.find-files.outputs.files_to_process != '[]'
        uses: actions/upload-artifact@v4
        with:
          name: deleted-files
          path: deleted_files.txt

  process-and-analyze-report:
    runs-on: ubuntu-latest
    needs: discover-and-scan
    if: needs.discover-and-scan.outputs.files_to_process != '[]'
    strategy:
      matrix:
        pdf_file: ${{ fromJson(needs.discover-and-scan.outputs.files_to_process) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install markitdown[pdf] google-generativeai google-api-python-client

      - name: Run PDF Converter
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GOOGLE_SEARCH_API_KEY: ${{ secrets.GOOGLE_SEARCH_API_KEY }}
          GOOGLE_CSE_ID: ${{ secrets.GOOGLE_CSE_ID }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          PDF_FILE="${{ matrix.pdf_file }}"
          PROMPT_PATH=".github/ai-prompts/pdf-to-markdown-prompt.md"
          PROMPT_VERSION=$(git log -n 1 --pretty=format:%s -- $PROMPT_PATH | grep -oP 'v\d+\.\d+(\.\d+)?' || echo 'v1.0')
          BRANCH_NAME=${{ github.head_ref || github.ref_name }}
          
          # Create a temporary file for the single PDF path
          echo "$PDF_FILE" > single_pdf_file.txt
          
          python .github/scripts/pdf-converter.py single_pdf_file.txt $PROMPT_PATH $PROMPT_VERSION $BRANCH_NAME --output-json conversions.json
        continue-on-error: true

      - name: Generate Conversion Summary
        run: |
          echo "### PDF to Markdown Conversion Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f conversions.json ]; then
            echo "| PDF File | Markdown File | Model Used | Status |
|---|---|---|---|" >> $GITHUB_STEP_SUMMARY
            # This assumes conversions.json is an array of objects with these keys.
            # You may need to adjust the jq query based on the actual structure of conversions.json.
            jq -r '.[] | "| `\(.pdf_file)` | `\(.markdown_file)` | \(.model // \"N/A\") | \(.status) |"' conversions.json >> $GITHUB_STEP_SUMMARY
          else
            echo "Conversion results file not found." >> $GITHUB_STEP_SUMMARY
          fi
        continue-on-error: true

      - name: Run Report Analyzer
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python .github/scripts/report-analyzer.py conversions.json --readme-path README.md --output-json analysis.json
        continue-on-error: true

      - name: Generate Analysis Summary
        run: |
          echo "### Report Analysis Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f analysis.json ]; then
            echo "| Markdown File | Category | Type | Analysis Method |
|---|---|---|---|" >> $GITHUB_STEP_SUMMARY
            # This assumes analysis.json is an array of objects with these keys.
            # You may need to adjust the jq query based on the actual structure of analysis.json.
            jq -r '.[] | "| `\(.markdown_file)` | \(.category) | \(.type) | \(.analysis_method // \"N/A\") |"' analysis.json >> $GITHUB_STEP_SUMMARY
          else
            echo "Analysis results file not found." >> $GITHUB_STEP_SUMMARY
          fi
        continue-on-error: true

      - name: Upload analysis results
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results-${{ hashFiles(matrix.pdf_file) }}
          path: analysis.json
        continue-on-error: true

  update-readme:
    runs-on: ubuntu-latest
    needs: [discover-and-scan, process-and-analyze-report]
    if: always() && needs.process-and-analyze-report.result != 'skipped'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull latest changes
        run: git pull

      - name: Download all analysis results
        uses: actions/download-artifact@v4
        with:
          name: analysis-results-*
          path: analysis-artifacts

      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-generativeai

      - name: Combine analysis results
        id: combine_analysis
        run: |
          mkdir -p combined_analysis
          echo "[]" > combined_analysis/all_analysis.json
          # Find all analysis.json files and merge them into one
          find analysis-artifacts -name "analysis.json" -print0 | while IFS= read -r -d $'
' file; do
            # Ensure the file is not empty and contains valid JSON
            if [ -s "$file" ] && jq -e . >/dev/null 2>&1 <"$file"; then
              jq -s '.[0] + .[1]' combined_analysis/all_analysis.json "$file" > temp.json && mv temp.json combined_analysis/all_analysis.json
            fi
          done
          
          # Check if the combined file is empty or contains only an empty array
          if [ ! -s combined_analysis/all_analysis.json ] || [ "$(jq 'length' combined_analysis/all_analysis.json)" -eq 0 ]; then
            echo "combined_analysis_exists=false" >> $GITHUB_OUTPUT
          else
            echo "combined_analysis_exists=true" >> $GITHUB_OUTPUT
          fi

      - name: Generate README Update Summary
        if: steps.combine_analysis.outputs.combined_analysis_exists == 'true'
        run: |
          echo "### Update Readme Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Markdown Entry | Type |
|---|---|" >> $GITHUB_STEP_SUMMARY
          # This assumes all_analysis.json is an array of objects with markdown_file and type keys.
          # You may need to adjust the jq query based on the actual structure of all_analysis.json.
          jq -r '.[] | "| `\(.markdown_file)` | \(.type // \"N/A\") |"' combined_analysis/all_analysis.json >> $GITHUB_STEP_SUMMARY

      - name: Run README Updater
        if: steps.combine_analysis.outputs.combined_analysis_exists == 'true'
        run: |
          python .github/scripts/readme-updater.py combined_analysis/all_analysis.json --readme-path README.md

      - name: Commit and Push Changes
        if: steps.combine_analysis.outputs.combined_analysis_exists == 'true'
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add README.md
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Update README with latest security reports"
            git push
          fi

  push-changes:
    runs-on: ubuntu-latest
    needs: [process-and-analyze-report, update-readme]
    if: always() && (needs.process-and-analyze-report.result == 'success' || needs.update-readme.result == 'success')
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0 # Fetch all history for git operations

      - name: Push all changes
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git pull --rebase # Rebase to avoid conflicts
          git push