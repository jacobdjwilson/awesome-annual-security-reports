name: Security Reports Processing Pipeline

on:
  push:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  
  pull_request:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  
  schedule:
    - cron: '0 12 * * *'
  
  workflow_dispatch:
    inputs:
      year_filter:
        description: 'Process PDFs from specific year'
        required: false
        type: string
      
      category_filter:
        description: 'Process PDFs from specific category'
        required: false
        type: choice
        options:
          - ''
          - '2020'
          - '2021'
          - '2022'
          - '2023'
          - '2024'
          - '2025'
          - '2026'
      
      organization_filter:
        description: 'Process PDFs matching organization'
        required: false
        type: string
      
      limit_count:
        description: 'Limit files to process (default: 10)'
        required: false
        default: '10'
        type: string
      
      skip_virus_scan:
        description: 'Skip VirusTotal scanning'
        required: false
        default: false
        type: boolean
      
      skip_existing_conversions:
        description: 'Skip files with existing conversions'
        required: false
        default: true
        type: boolean

permissions:
  contents: write
  pull-requests: write

jobs:
  discover-and-scan:
    runs-on: ubuntu-latest
    outputs:
      files_to_process: ${{ steps.find-files.outputs.files_to_process }}
      has_files: ${{ steps.find-files.outputs.has_files }}
      scan_mode: ${{ steps.find-files.outputs.scan_mode }}
      file_count: ${{ steps.find-files.outputs.file_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Find and validate PDF files
        id: find-files
        run: |
          > files_to_process.txt
          > deleted_files.txt
          > invalid_files.txt
          
          echo "======================================================================"
          echo "FILE DISCOVERY"
          echo "======================================================================"
          
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "Mode: Manual with filters"
            echo "scan_mode=manual" >> $GITHUB_OUTPUT
            
            FIND_CMD="find 'Annual Security Reports' -name '*.pdf' -type f"
            
            if [ -n "${{ github.event.inputs.year_filter }}" ]; then
              YEAR="${{ github.event.inputs.year_filter }}"
              FIND_CMD="$FIND_CMD -path '*/$YEAR/*'"
              echo "Filter: Year = $YEAR"
            fi
            
            if [ -n "${{ github.event.inputs.category_filter }}" ]; then
              CAT="${{ github.event.inputs.category_filter }}"
              FIND_CMD="$FIND_CMD -path '*/$CAT/*'"
              echo "Filter: Category = $CAT"
            fi
            
            eval $FIND_CMD > all_found.txt
            
            if [ -n "${{ github.event.inputs.organization_filter }}" ]; then
              ORG="${{ github.event.inputs.organization_filter }}"
              grep -i "$ORG" all_found.txt > filtered.txt || true
              mv filtered.txt all_found.txt
              echo "Filter: Organization = $ORG"
            fi
            
            if [ "${{ github.event.inputs.skip_existing_conversions }}" == "true" ]; then
              > needs_conversion.txt
              while IFS= read -r pdf_path; do
                md_path=$(echo "$pdf_path" | sed 's/Annual Security Reports/Markdown Conversions/' | sed 's/\.pdf$/.md/')
                if [ ! -f "$md_path" ]; then
                  echo "$pdf_path" >> needs_conversion.txt
                fi
              done < all_found.txt
              mv needs_conversion.txt all_found.txt
              echo "Filter: Skip existing = enabled"
            fi
            
            LIMIT="${{ github.event.inputs.limit_count }}"
            if [ -z "$LIMIT" ]; then
              LIMIT=10
            fi
            
            head -n "$LIMIT" all_found.txt > files_to_process.txt
            echo "Filter: Limit = $LIMIT files"
            
          elif [ "${{ github.event_name }}" == "schedule" ]; then
            echo "Mode: Scheduled"
            echo "scan_mode=scheduled" >> $GITHUB_OUTPUT
            
            find "Annual Security Reports" -name "*.pdf" -type f > all_pdfs.txt
            
            > missing_conversions.txt
            while IFS= read -r pdf_path; do
              md_path=$(echo "$pdf_path" | sed 's/Annual Security Reports/Markdown Conversions/' | sed 's/\.pdf$/.md/')
              if [ ! -f "$md_path" ]; then
                echo "$pdf_path" >> missing_conversions.txt
              fi
            done < all_pdfs.txt
            
            if [ -s missing_conversions.txt ]; then
              cat missing_conversions.txt | xargs ls -rt | head -n 1 > files_to_process.txt
            fi
            
          elif [ "${{ github.event_name }}" == "push" ]; then
            echo "Mode: Push"
            echo "scan_mode=push" >> $GITHUB_OUTPUT
            git diff --name-only HEAD~1 HEAD | grep 'Annual Security Reports/.*\.pdf$' > files_to_process.txt || true
            
          else
            echo "Mode: Pull request"
            echo "scan_mode=pr" >> $GITHUB_OUTPUT
            git diff --name-only --diff-filter=AM origin/main...HEAD | grep 'Annual Security Reports/.*\.pdf$' > files_to_process.txt || true
          fi
          
          # Validate files with detailed reasons
          if [ -s files_to_process.txt ]; then
            VALID_FILES=""
            
            while IFS= read -r FILE_PATH; do
              REASON=""
              
              if [ ! -f "$FILE_PATH" ]; then
                REASON="File Not Found"
                echo "$FILE_PATH|$REASON" >> invalid_files.txt
                echo "âŠ˜ Not found: $FILE_PATH"
                continue
              fi
              
              FILE_SIZE=$(stat -c%s "$FILE_PATH")
              if [ "$FILE_SIZE" -gt 104857600 ]; then
                SIZE_MB=$((FILE_SIZE/1024/1024))
                REASON="Size Limit Exceeded ($SIZE_MB MB > 100 MB)"
                echo "$FILE_PATH|$REASON" >> invalid_files.txt
                echo "âŠ˜ Too large: $FILE_PATH ($SIZE_MB MB)"
                continue
              fi
              
              MAGIC=$(head -c 4 "$FILE_PATH" || true)
              if [ "$MAGIC" != "%PDF" ]; then
                REASON="Invalid PDF (Magic number: '$MAGIC')"
                echo "$FILE_PATH|$REASON" >> invalid_files.txt
                echo "âŠ˜ Invalid PDF: $FILE_PATH"
                continue
              fi
              
              VALID_FILES="$VALID_FILES$FILE_PATH\n"
              echo "âœ“ Valid: $FILE_PATH"
            done < files_to_process.txt
            
            echo -e "$VALID_FILES" | sed '/^$/d' > files_to_process.txt
          fi
          
          # Set outputs and generate summary
          if [ -s files_to_process.txt ]; then
            FILE_COUNT=$(wc -l < files_to_process.txt)
            echo "has_files=true" >> $GITHUB_OUTPUT
            echo "file_count=$FILE_COUNT" >> $GITHUB_OUTPUT
            echo "files_to_process=$(cat files_to_process.txt | tr '\n' ',' | sed 's/,$//')" >> $GITHUB_OUTPUT
            echo "âœ“ $FILE_COUNT files to process"
            
            # Summary
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ“‹ Files to Process" >> $GITHUB_STEP_SUMMARY
            echo "**Count:** $FILE_COUNT" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat files_to_process.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "has_files=false" >> $GITHUB_OUTPUT
            echo "file_count=0" >> $GITHUB_OUTPUT
            echo "âŠ˜ No files to process"
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### âŠ˜ No Files to Process" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Invalid files summary
          if [ -s invalid_files.txt ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### âš ï¸ Invalid Files Skipped" >> $GITHUB_STEP_SUMMARY
            echo "| File | Reason |" >> $GITHUB_STEP_SUMMARY
            echo "|------|--------|" >> $GITHUB_STEP_SUMMARY
            while IFS='|' read -r file reason; do
              echo "| \`$(basename "$file")\` | $reason |" >> $GITHUB_STEP_SUMMARY
            done < invalid_files.txt
          fi

      - name: Upload file list
        if: steps.find-files.outputs.has_files == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: file-lists
          path: |
            files_to_process.txt
            invalid_files.txt

  convert-pdf-to-markdown:
    runs-on: ubuntu-latest
    needs: discover-and-scan
    if: needs.discover-and-scan.outputs.has_files == 'true'
    outputs:
      conversion_success: ${{ steps.converter.outputs.conversion_success }}
      successful_count: ${{ steps.converter.outputs.successful_count }}
      failed_count: ${{ steps.converter.outputs.failed_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download file list
        uses: actions/download-artifact@v4
        with:
          name: file-lists

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            poppler-utils \
            tesseract-ocr \
            libtesseract-dev \
            libleptonica-dev
          
          pip install --break-system-packages \
            "markitdown[pdf,ocr]" \
            "pypdf[crypto]" \
            google-generativeai \
            google-ai-generativelanguage \
            Pillow \
            pytesseract

      - name: Run PDF converter
        id: converter
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python .github/scripts/pdf-converter.py \
            --file-list files_to_process.txt \
            --output-json conversions.json \
            --artifacts-dir .github/artifacts
          
          # Count results
          SUCCESSFUL=$(jq '[.[] | select(.status == "success")] | length' conversions.json)
          FAILED=$(jq '[.[] | select(.status != "success")] | length' conversions.json)
          PARTIAL=$(jq '[.[] | select(.message | contains("partial"))] | length' conversions.json)
          
          echo "conversion_success=true" >> $GITHUB_OUTPUT
          echo "successful_count=$SUCCESSFUL" >> $GITHUB_OUTPUT
          echo "failed_count=$FAILED" >> $GITHUB_OUTPUT
          
          # Summary
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“„ PDF Conversion Results" >> $GITHUB_STEP_SUMMARY
          echo "| Status | Count |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| âœ… Successful | $SUCCESSFUL |" >> $GITHUB_STEP_SUMMARY
          echo "| âŒ Failed | $FAILED |" >> $GITHUB_STEP_SUMMARY
          echo "| âš ï¸ Partial | $PARTIAL |" >> $GITHUB_STEP_SUMMARY
          
          # Detailed conversion list
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>ðŸ“‹ Conversion Details</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Organization | Status | Message |" >> $GITHUB_STEP_SUMMARY
          echo "|--------------|--------|---------|" >> $GITHUB_STEP_SUMMARY
          jq -r '.[] | "| \(.organization_name) | \(.status) | \(.message) |"' conversions.json >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY
          
          # Warnings for partial conversions
          if [ "$PARTIAL" -gt 0 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### âš ï¸ Conversion Warnings" >> $GITHUB_STEP_SUMMARY
            jq -r '.[] | select(.message | contains("partial")) | 
              "- **\(.organization_name)**: \(.message)"' conversions.json >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload conversions
        uses: actions/upload-artifact@v4
        with:
          name: conversion-results
          path: conversions.json

      - name: Upload markdown files
        uses: actions/upload-artifact@v4
        with:
          name: markdown-conversions
          path: Markdown Conversions/
          if-no-files-found: ignore

  analyze-reports:
    runs-on: ubuntu-latest
    needs: [discover-and-scan, convert-pdf-to-markdown]
    if: needs.discover-and-scan.outputs.has_files == 'true'
    outputs:
      analysis_success: ${{ steps.report-analysis.outputs.analysis_success }}
      analysis_count: ${{ steps.report-analysis.outputs.analysis_count }}
      ai_model: ${{ steps.report-analysis.outputs.ai_model }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download conversions
        uses: actions/download-artifact@v4
        with:
          name: conversion-results

      - name: Download markdown files
        uses: actions/download-artifact@v4
        with:
          name: markdown-conversions
          path: Markdown Conversions/

      - name: Pre-Analysis Verification
        id: verify
        run: |
          echo "Verifying conversions.json..."
          
          # Check file exists
          if [ ! -f conversions.json ]; then
            echo "âŒ ERROR: conversions.json not found"
            exit 1
          fi
          
          # Check file size
          FILE_SIZE=$(stat -c%s conversions.json)
          echo "File size: $FILE_SIZE bytes"
          
          if [ "$FILE_SIZE" -lt 10 ]; then
            echo "âŒ ERROR: conversions.json is too small ($FILE_SIZE bytes)"
            exit 1
          fi
          
          # Validate JSON
          if ! jq empty conversions.json 2>/dev/null; then
            echo "âŒ ERROR: conversions.json is not valid JSON"
            exit 1
          fi
          
          # Check for successful conversions
          SUCCESSFUL=$(jq '[.[] | select(.status == "success")] | length' conversions.json)
          echo "Successful conversions: $SUCCESSFUL"
          
          if [ "$SUCCESSFUL" -eq 0 ]; then
            echo "âš ï¸ WARNING: No successful conversions to analyze"
            echo "has_successful=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "has_successful=true" >> $GITHUB_OUTPUT
          echo "âœ… Pre-analysis verification passed"

      - name: Install dependencies
        if: steps.verify.outputs.has_successful == 'true'
        run: |
          pip install --break-system-packages \
            google-generativeai \
            google-ai-generativelanguage

      - name: Run report analyzer
        id: report-analysis
        if: steps.verify.outputs.has_successful == 'true'
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          echo "Running report analyzer..."
          
          python .github/scripts/report-analyzer.py \
            conversions.json \
            --output-json analysis.json \
            --artifacts-dir .github/artifacts
          
          if [ -f analysis.json ]; then
            ANALYSIS_COUNT=$(jq 'length' analysis.json)
            AI_MODEL=$(jq -r '.[0].ai_processed // "none"' analysis.json)
            
            echo "analysis_success=true" >> $GITHUB_OUTPUT
            echo "analysis_count=$ANALYSIS_COUNT" >> $GITHUB_OUTPUT
            echo "ai_model=gemini-3-flash-preview" >> $GITHUB_OUTPUT
            
            # Analysis preview
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ¤– AI Analysis Results" >> $GITHUB_STEP_SUMMARY
            echo "**Model Used:** gemini-3-flash-preview" >> $GITHUB_STEP_SUMMARY
            echo "**Reports Analyzed:** $ANALYSIS_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Organization | Title | Year | Category |" >> $GITHUB_STEP_SUMMARY
            echo "|--------------|-------|------|----------|" >> $GITHUB_STEP_SUMMARY
            jq -r '.[] | "| \(.organization) | \(.title) | \(.year) | \(.category) |"' analysis.json >> $GITHUB_STEP_SUMMARY
            
            echo "âœ“ Analyzed $ANALYSIS_COUNT reports"
          else
            echo "âŒ ERROR: analysis.json not created"
            echo "analysis_success=false" >> $GITHUB_OUTPUT
            echo "analysis_count=0" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Upload analysis
        if: steps.verify.outputs.has_successful == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: analysis.json

  update-readme:
    runs-on: ubuntu-latest
    needs: [discover-and-scan, convert-pdf-to-markdown, analyze-reports]
    if: |
      needs.discover-and-scan.outputs.has_files == 'true' &&
      needs.analyze-reports.outputs.analysis_success == 'true'
    outputs:
      readme_updated: ${{ steps.readme_update.outputs.readme_updated }}
      pr_number: ${{ steps.create_pr.outputs.pull-request-number }}
      pr_title: ${{ steps.generate_pr_content.outputs.pr_title }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download analysis
        uses: actions/download-artifact@v4
        with:
          name: analysis-results

      - name: Download markdown files
        uses: actions/download-artifact@v4
        with:
          name: markdown-conversions
          path: Markdown Conversions/

      - name: Update README
        id: readme_update
        run: |
          echo "Updating README..."
          
          # Run with validation
          python .github/scripts/readme-updater.py \
            analysis.json \
            --readme-path README.md \
            --artifacts-dir .github/artifacts \
            --validate-toc
          
          # Check for changes
          if git diff --quiet README.md "Markdown Conversions/"; then
            echo "readme_updated=false" >> $GITHUB_OUTPUT
            echo "âŠ˜ No changes (entries already exist)"
          else
            echo "readme_updated=true" >> $GITHUB_OUTPUT
            
            # Count changes
            ADDED=$(git diff README.md | grep '^+' | grep -v '^+++' | wc -l)
            REMOVED=$(git diff README.md | grep '^-' | grep -v '^---' | wc -l)
            
            echo "changes_added=$ADDED" >> $GITHUB_OUTPUT
            echo "changes_removed=$REMOVED" >> $GITHUB_OUTPUT
            echo "âœ“ README updated ($ADDED additions, $REMOVED deletions)"
          fi

      - name: Generate PR content
        id: generate_pr_content
        if: steps.readme_update.outputs.readme_updated == 'true'
        run: |
          # Generate dynamic PR title
          REPORT_COUNT=$(jq 'length' analysis.json)
          
          if [ "$REPORT_COUNT" -eq 1 ]; then
            # Single report - use specific title
            ORG=$(jq -r '.[0].organization' analysis.json)
            TITLE=$(jq -r '.[0].title' analysis.json)
            YEAR=$(jq -r '.[0].year' analysis.json)
            PR_TITLE="Add $ORG $TITLE ($YEAR)"
          else
            # Multiple reports - use count
            PR_TITLE="Update Security Reports - $REPORT_COUNT Report(s)"
          fi
          
          echo "pr_title=$PR_TITLE" >> $GITHUB_OUTPUT
          
          # Generate detailed PR body
          cat > pr_body.md << 'EOFPR'
          ## ðŸ“Š Security Reports Update
          
          **Mode:** ${{ needs.discover-and-scan.outputs.scan_mode }}
          **Reports Processed:** $(jq 'length' analysis.json)
          **AI Model:** ${{ needs.analyze-reports.outputs.ai_model }}
          
          ### ðŸ“„ Reports Included
          
          EOFPR
          
          # Add report details
          jq -r '.[] | "#### \(.organization) - \(.title) (\(.year))\n\n**Category:** \(.category)\n**Type:** \(.type)\n\n**Summary:** \(.summary)\n\n---\n"' analysis.json >> pr_body.md
          
          # Add statistics
          cat >> pr_body.md << 'EOFPR'
          
          ### ðŸ“ˆ Statistics
          
          - **Conversions:** ${{ needs.convert-pdf-to-markdown.outputs.successful_count }} successful, ${{ needs.convert-pdf-to-markdown.outputs.failed_count }} failed
          - **README Changes:** ${{ steps.readme_update.outputs.changes_added }} additions, ${{ steps.readme_update.outputs.changes_removed }} deletions
          
          ---
          *Auto-generated by Security Reports Pipeline*
          EOFPR

      - name: Create Pull Request
        id: create_pr
        if: steps.readme_update.outputs.readme_updated == 'true'
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "ðŸ“„ ${{ steps.generate_pr_content.outputs.pr_title }}"
          title: "${{ steps.generate_pr_content.outputs.pr_title }}"
          body-path: pr_body.md
          branch: security-reports-update-${{ github.run_id }}
          delete-branch: true
          labels: |
            automated
            security-reports
          add-paths: |
            README.md
            Markdown Conversions/

  generate-summary:
    runs-on: ubuntu-latest
    needs: [discover-and-scan, convert-pdf-to-markdown, analyze-reports, update-readme]
    if: always()
    
    steps:
      - name: Generate comprehensive summary
        run: |
          echo "## ðŸŽ¯ Pipeline Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run ID:** ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Mode:** ${{ needs.discover-and-scan.outputs.scan_mode }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Job status table
          echo "### ðŸ“Š Job Status" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status | Details |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| Discovery | ${{ needs.discover-and-scan.result }} | ${{ needs.discover-and-scan.outputs.file_count }} files found |" >> $GITHUB_STEP_SUMMARY
          echo "| Conversion | ${{ needs.convert-pdf-to-markdown.result }} | ${{ needs.convert-pdf-to-markdown.outputs.successful_count }} successful |" >> $GITHUB_STEP_SUMMARY
          echo "| Analysis | ${{ needs.analyze-reports.result }} | ${{ needs.analyze-reports.outputs.analysis_count }} analyzed |" >> $GITHUB_STEP_SUMMARY
          echo "| README Update | ${{ needs.update-readme.result }} | Updated: ${{ needs.update-readme.outputs.readme_updated }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # PR link if created
          if [ -n "${{ needs.update-readme.outputs.pr_number }}" ]; then
            echo "### âœ… Pull Request Created" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Title:** ${{ needs.update-readme.outputs.pr_title }}" >> $GITHUB_STEP_SUMMARY
            echo "**PR #${{ needs.update-readme.outputs.pr_number }}**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "[ðŸ“‹ View Pull Request](https://github.com/${{ github.repository }}/pull/${{ needs.update-readme.outputs.pr_number }})" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.update-readme.outputs.readme_updated }}" == "false" ]; then
            echo "### â„¹ï¸ No Updates Needed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All processed reports already exist in README with current year." >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*Pipeline completed at $(date -u +'%Y-%m-%d %H:%M:%S UTC')*" >> $GITHUB_STEP_SUMMARY