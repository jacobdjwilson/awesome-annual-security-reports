name: PDF to Markdown Conversion

on:
  push:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  pull_request:
    branches: [main, development]
    paths:
      - 'Annual Security Reports/**/*.pdf'
  workflow_dispatch:

jobs:
  convert-pdf-to-markdown:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install 'markitdown[pdf]' google-generativeai google-api-python-client
      
      - name: Find changed PDF files
        id: find-pdfs
        run: |
          CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD || echo ${GITHUB_REF#refs/heads/})
          echo "Current branch: $CURRENT_BRANCH"
          
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            # For pull requests
            CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }} | grep -E "Annual Security Reports/.*\.pdf$" || true)
          elif [[ -n "${{ github.event.before }}" && "${{ github.event.before }}" != "0000000000000000000000000000000000000000" ]]; then
            # For direct pushes
            CHANGED_FILES=$(git diff --name-only ${{ github.event.before }} ${{ github.event.after }} | grep -E "Annual Security Reports/.*\.pdf$" || true)
          else
            # For manual runs or initial pushes
            CHANGED_FILES=$(find "Annual Security Reports" -name "*.pdf" 2>/dev/null || true)
          fi
          
          if [[ -z "$CHANGED_FILES" ]]; then
            echo "No PDF files found. Exiting."
            echo "pdfs_changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "pdfs_changed=true" >> $GITHUB_OUTPUT
          echo "pdf_files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "branch=$CURRENT_BRANCH" >> $GITHUB_OUTPUT
      
      - name: Verify prompt file exists
        id: check-prompt
        run: |
          PROMPT_PATH=".github/ai-prompts/pdf-to-markdown-prompt.md"
          if [ -f "$PROMPT_PATH" ]; then
            echo "prompt_exists=true" >> $GITHUB_OUTPUT
            echo "Found prompt file at $PROMPT_PATH"
            PROMPT_VERSION=$(git log -n 1 --pretty=format:"%s" -- "$PROMPT_PATH" | grep -oP "v\d+\.\d+(\.\d+)?" || echo "v1.0")
            echo "prompt_version=$PROMPT_VERSION" >> $GITHUB_OUTPUT
          else
            echo "prompt_exists=false" >> $GITHUB_OUTPUT
            echo "Prompt file not found at $PROMPT_PATH"
          fi
      
      - name: Create Python script
        run: |
          cat > process_pdfs.py << 'ENDPYTHONSCRIPT'
          import os
          import sys
          import google.generativeai as genai
          from pathlib import Path
          import subprocess
          from markitdown import MarkItDown
          from googleapiclient.discovery import build
          from googleapiclient.errors import HttpError
          
          # Setup Gemini API
          genai.configure(api_key=os.environ["GEMINI_API_KEY"])
          
          # Print available models for debugging
          def list_available_models():
              try:
                  print("Attempting to list available models...")
                  models = genai.list_models()
                  print("Available models:")
                  for model in models:
                      print(f"- {model.name}")
                  return models
              except Exception as e:
                  print(f"Error listing models: {str(e)}")
                  return []
          
          # List available models
          available_models = list_available_models()
          
          # Define models to try in order of preference - using currently available models
          MODELS = ["gemini-2.5-flash", "gemini-2.0-flash", "gemini-1.5-flash"]
          
          # Get the first available model
          MODEL = None
          for model in MODELS:
              try:
                  print(f"Attempting to use model: {model}")
                  test_model = genai.GenerativeModel(model)
                  # Test a simple generation to verify it works
                  test_response = test_model.generate_content("Hello")
                  MODEL = model
                  print(f"Successfully verified model: {MODEL}")
                  break
              except Exception as e:
                  print(f"Model {model} not available or failed verification: {str(e)}")
                  continue
          
          if not MODEL:
              print("No models available. Exiting.")
              sys.exit(1)
          
          def read_prompt_file(path):
              try:
                  with open(path, "r") as file:
                      return file.read()
              except Exception as e:
                  print(f"Error reading prompt file: {str(e)}")
                  sys.exit(1)
          
          def extract_text_from_pdf(pdf_path):
              try:
                  # Use markitdown to extract text from PDF
                  print(f"Extracting text from PDF: {pdf_path}")
                  md = MarkItDown(enable_plugins=False)
                  result = md.convert(str(pdf_path))
                  text_length = len(result.text_content)
                  print(f"Successfully extracted {text_length} characters from PDF")
                  return result.text_content
              except Exception as e:
                  print(f"Error extracting text from PDF: {str(e)}")
                  raise
          
          def perform_google_search(query, api_key, cse_id):
              """Performs a Google Custom Search and returns the first result URL."""
              try:
                  service = build("customsearch", "v1", developerKey=api_key)
                  res = service.cse().list(q=query, cx=cse_id, num=1).execute()
                  if 'items' in res and len(res['items']) > 0:
                      print(f"Google Search found URL: {res['items'][0]['link']}")
                      return res['items'][0]['link']
                  else:
                      print("No Google search results found.")
                      return None
              except HttpError as e:
                  print(f"Google Search API error: {e}")
                  return None
              except Exception as e:
                  print(f"An unexpected error occurred during Google Search: {e}")
                  return None
          
          def generate_markdown_with_ai(pdf_text, prompt_text, organization_url=None):
              try:
                  print(f"Generating markdown with {MODEL}...")
                  model = genai.GenerativeModel(MODEL)
                  
                  full_prompt = f"{prompt_text}\n\n"
                  if organization_url:
                      full_prompt += f"The official report URL is: {organization_url}\n\n"
                  full_prompt += f"# Report Content Below\n\n{pdf_text}"
                  
                  # Set generation parameters for better output
                  generation_config = {
                      "temperature": 0.2,  # Lower temperature for more predictable output
                      "max_output_tokens": 8192,
                  }
                  
                  response = model.generate_content(
                      full_prompt,
                      generation_config=generation_config
                  )
                  
                  # Log prompt feedback
                  if response.prompt_feedback:
                      print(f"Prompt feedback: {response.prompt_feedback}")

                  # Log candidate details for debugging
                  if response.candidates:
                      for i, candidate in enumerate(response.candidates):
                          print(f"Candidate {i} finish reason: {candidate.finish_reason}")
                          if candidate.safety_ratings:
                              print(f"Candidate {i} safety ratings: {candidate.safety_ratings}")
                  
                  if not response.text:
                      error_message = "The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned."
                      if response.candidates and response.candidates[0].finish_reason:
                          error_message += f" The candidate's finish_reason is {response.candidates[0].finish_reason}."
                      if response.candidates and response.candidates[0].safety_ratings:
                          error_message += f" Safety ratings: {response.candidates[0].safety_ratings}."
                      raise ValueError(error_message)

                  print(f"Successfully generated markdown ({len(response.text)} characters)")
                  return response.text
              except Exception as e:
                  print(f"Error generating markdown with AI: {str(e)}")
                  raise
          
          def process_pdf(pdf_path, prompt_path, prompt_version, branch):
              """Process a PDF file and convert it to markdown
              
              Args:
                  pdf_path: Path to the PDF file
                  prompt_path: Path to the prompt file
                  prompt_version: Version of the prompt
                  branch: Current branch (main or development)
                  
              Returns:
                  bool: True if successful, False otherwise
              """
              print(f"Processing: {pdf_path} (Branch: {branch})")
              
              # Read the prompt from repository
              prompt_text = read_prompt_file(prompt_path)
              print(f"Loaded prompt file ({len(prompt_text)} characters)")
              
              # Extract text from PDF using markitdown
              pdf_text = extract_text_from_pdf(pdf_path)
              
              # Extract organization and title from PDF filename
              # Example: Annual Security Reports/2024/Varonis - The Identity Crisis 2024.pdf
              # Organization: Varonis
              # Title: The Identity Crisis 2024
              filename_stem = pdf_path.stem
              parts = filename_stem.split(' - ', 1)
              organization_name = parts[0].strip() if len(parts) > 0 else ""
              report_title = parts[1].strip() if len(parts) > 1 else filename_stem
              
              # Perform Google Search for the official report URL
              google_search_api_key = os.environ.get("GOOGLE_SEARCH_API_KEY")
              google_cse_id = os.environ.get("GOOGLE_CSE_ID")
              organization_url = None
              
              if google_search_api_key and google_cse_id:
                  search_query = f"{organization_name} {report_title} report"
                  print(f"Performing Google search for: '{search_query}'")
                  organization_url = perform_google_search(search_query, google_search_api_key, google_cse_id)
              else:
                  print("Google Search API keys not provided. Skipping URL search.")
              
              # Generate markdown with Gemini, passing the organization URL
              markdown_content = generate_markdown_with_ai(pdf_text, prompt_text, organization_url)
              
              # Determine the output path that matches the input directory structure
              # e.g., Annual Security Reports/2025/file.pdf -> Markdown Conversions/2025/file.md
              relative_path = pdf_path.relative_to(Path("Annual Security Reports"))
              output_dir = Path("Markdown Conversions") / relative_path.parent
              output_path = output_dir / f"{pdf_path.stem}.md"
              
              print(f"Writing output to: {output_path}")
              
              # Create output directory if it doesn't exist
              os.makedirs(output_dir, exist_ok=True)
              
              # Write the markdown content to file, overwriting if it already exists
              with open(output_path, "w", encoding="utf-8") as f:
                  f.write(markdown_content)
              
              # Check if file was created or updated
              if not output_path.exists():
                  print(f"Error: Failed to create {output_path}")
                  return False
                  
              print(f"Created/Updated: {output_path}")
              
              # Add the converted file path to the list of converted files
              with open(os.environ.get("CONVERTED_FILES_PATH", "converted_files.txt"), "a") as f:
                  f.write(f"{output_path}\n")
              
              # Commit the file
              try:
                  # Add the file
                  subprocess.run(["git", "config", "user.name", "GitHub Action"], check=True)
                  subprocess.run(["git", "config", "user.email", "action@github.com"], check=True)
                  subprocess.run(["git", "add", str(output_path)], check=True)
                  
                  # Check if file is modified or new
                  status_result = subprocess.run(
                      ["git", "status", "--porcelain", str(output_path)], 
                      capture_output=True, 
                      text=True
                  )
                  
                  if status_result.returncode != 0:
                      print(f"Warning: Git status check failed: {status_result.stderr}")
                      action = "Updated"
                  else:
                      status = status_result.stdout.strip()
                      action = "Updated" if status.startswith("M") else "Created"
                  
                  # Commit the file
                  commit_message = f"{action} {output_path.name} from {pdf_path.name} using AI Prompt {prompt_version} (Model {MODEL}, Branch {branch})"
                  subprocess.run(["git", "commit", "-m", commit_message], check=True)
                  print(f"Committed changes: {commit_message}")
                  return {
                      "pdf_path": str(pdf_path),
                      "output_path": str(output_path),
                      "model_used": MODEL,
                      "status": "Converted Successfully"
                  }
              except Exception as e:
                  print(f"Error during git operations: {str(e)}")
                  return {
                      "pdf_path": str(pdf_path),
                      "output_path": "", # No output path if failed
                      "model_used": MODEL,
                      "status": f"Failed: {str(e)}"
                  }
          
          def main():
              if len(sys.argv) < 4:
                  print("Usage: python process_pdfs.py <pdf_paths_file> <prompt_path> <prompt_version> <branch>")
                  return 1
              
              pdf_paths_file = sys.argv[1]
              prompt_path = sys.argv[2]
              prompt_version = sys.argv[3]
              branch = sys.argv[4] if len(sys.argv) > 4 else "unknown"
              
              # Create or clear the converted files list
              converted_files_path = os.environ.get("CONVERTED_FILES_PATH", "converted_files.txt")
              with open(converted_files_path, "w") as f:
                  f.write("")  # Just create/clear the file
              
              # Read PDF paths
              with open(pdf_paths_file, "r") as f:
                  pdf_paths = [line.strip() for line in f.readlines()]
              
              print(f"Processing {len(pdf_paths)} PDF files on branch {branch}")
              
              success_count = 0
              all_results = [] # Initialize all_results list
              
              # Process each PDF
              for pdf_path_str in pdf_paths:
                  pdf_path = Path(pdf_path_str)
                  try:
                      result = process_pdf(pdf_path, prompt_path, prompt_version, branch)
                      all_results.append(result)
                      if result["status"] == "Converted Successfully":
                          success_count += 1
                  except Exception as e:
                      print(f"Error processing {pdf_path}: {str(e)}")
                      all_results.append({
                          "pdf_path": str(pdf_path),
                          "output_path": "",
                          "model_used": MODEL,
                          "status": f"Failed: {str(e)}"
                      })
              
              print(f"Successfully processed {success_count}/{len(pdf_paths)} PDFs")
              
              # Generate and write summary to GITHUB_STEP_SUMMARY
              summary_path = os.environ.get('GITHUB_STEP_SUMMARY', 'summary.md')
              with open(summary_path, 'a', encoding='utf-8') as f:
                  f.write("## 📄 PDF to Markdown Conversion Summary\n\n")
                  f.write("| PDF File | Markdown Output | Model Used | Status |\n")
                  f.write("|----------|-----------------|------------|--------|\n")
                  for result in all_results:
                      status_icon = "✅" if result['status'] == 'Converted Successfully' else "❌"
                      f.write(f"| {result['pdf_path']} | {result['output_path']} | {result['model_used']} | {status_icon} {result['status']} |\n")
                  
                  f.write(f"\n### Summary\n")
                  f.write(f"- Successfully converted: {success_count}\n")
                  f.write(f"- Failed conversions: {len(pdf_paths) - success_count}\n")
                  f.write(f"- Total PDFs processed: {len(pdf_paths)}\n")
                  
                  f.write("\n### About the Conversion\n")
                  f.write("- PDF text extracted using `markitdown[pdf]`.\n")
                  f.write("- Markdown generated using Google Gemini API.\n")
                  f.write("- AI prompt from `.github/ai-prompts/pdf-to-markdown-prompt.md`.\n")
                  f.write("- Output files are committed to the repository.\n")

              return 0 if success_count > 0 else 1
          
          if __name__ == "__main__":
              sys.exit(main())
          ENDPYTHONSCRIPT

      - name: Process PDF files
        if: steps.find-pdfs.outputs.pdfs_changed == 'true' && steps.check-prompt.outputs.prompt_exists == 'true'
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GOOGLE_SEARCH_API_KEY: ${{ secrets.GOOGLE_SEARCH_API_KEY }}
          GOOGLE_CSE_ID: ${{ secrets.GOOGLE_CSE_ID }}
          PROMPT_VERSION: ${{ steps.check-prompt.outputs.prompt_version }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BRANCH: ${{ steps.find-pdfs.outputs.branch }}
          CONVERTED_FILES_PATH: "converted_files.txt"
          GITHUB_STEP_SUMMARY: ${{ github.step_summary }}
        run: |
          # Create a file with the list of PDF paths
          echo "${{ steps.find-pdfs.outputs.pdf_files }}" > pdf_paths.txt
          
          # Run the Python script
          python process_pdfs.py pdf_paths.txt ".github/ai-prompts/pdf-to-markdown-prompt.md" "$PROMPT_VERSION" "$BRANCH"
          
          # Push changes
          git push https://${GITHUB_ACTOR}:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git HEAD:${GITHUB_REF}
      
      - name: Upload converted files info
        if: steps.find-pdfs.outputs.pdfs_changed == 'true' && steps.check-prompt.outputs.prompt_exists == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: converted_file_info
          path: converted_files.txt
          retention-days: 1
      
      - name: Error - Prompt file missing
        if: steps.find-pdfs.outputs.pdfs_changed == 'true' && steps.check-prompt.outputs.prompt_exists != 'true'
        run: |
          echo "Error: Prompt file not found at .github/ai-prompts/pdf-to-markdown-prompt.md"
          echo "Please ensure the prompt file exists in your repository."
          exit 1
