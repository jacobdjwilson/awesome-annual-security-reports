name: PDF Processing Workflow

on:
  push:
    branches:
      - main
      - development
    paths:
      - 'Annual Security Reports/**/*.pdf'

jobs:
  detect-pdfs:
    name: Detect New PDF Files
    runs-on: ubuntu-latest
    outputs:
      pdf_files: ${{ steps.find-pdfs.outputs.pdf_files }}
      pdf_count: ${{ steps.find-pdfs.outputs.pdf_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # To get the previous commit for comparison
      
      - name: Find new PDF files
        id: find-pdfs
        run: |
          # Get files changed in the last commit
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD | grep -E "Annual Security Reports/.+\.pdf$" || echo "")
          
          if [ -z "$CHANGED_FILES" ]; then
            echo "No new PDF files detected"
            echo "pdf_files=[]" >> $GITHUB_OUTPUT
            echo "pdf_count=0" >> $GITHUB_OUTPUT
          else
            # Format as JSON array
            JSON_FILES=$(echo "$CHANGED_FILES" | jq -R . | jq -s .)
            echo "pdf_files=$JSON_FILES" >> $GITHUB_OUTPUT
            echo "pdf_count=$(echo "$CHANGED_FILES" | wc -l)" >> $GITHUB_OUTPUT
            echo "Found new PDF files: $JSON_FILES"
          fi

  hybrid-analysis-scan:
    name: Security Scan with Hybrid Analysis
    needs: detect-pdfs
    if: needs.detect-pdfs.outputs.pdf_count != '0'
    runs-on: ubuntu-latest
    outputs:
      clean_pdfs: ${{ steps.scan-results.outputs.clean_pdfs }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Scan PDFs with Hybrid Analysis
        id: scan-pdfs
        env:
          HYBRID_ANALYSIS_API_KEY: ${{ secrets.HYBRID_ANALYSIS_API_KEY }}
          PDF_FILES: ${{ needs.detect-pdfs.outputs.pdf_files }}
        run: |
          echo "Scanning PDF files with Hybrid Analysis..."
          python - <<'EOF' > scan_results.json
          import os
          import json
          import time
          import requests
          import sys

          # Configuration
          API_BASE = "https://www.hybrid-analysis.com/api/v2"
          SUBMIT_URL = f"{API_BASE}/submit/file"
          HEADERS = {
              "api-key": os.environ["HYBRID_ANALYSIS_API_KEY"],
              "User-Agent": "Github Actions Falcon Hybrid Analysis"
          }
          ENVIRONMENT_ID = 300  # Windows 11 64-bit
          MAX_RETRIES = 5
          MAX_POLL_ATTEMPTS = 30
          POLL_INTERVAL = 20  # seconds

          # Get PDF files from environment variable
          pdf_files = json.loads(os.environ["PDF_FILES"])
          results = []

          for pdf_file in pdf_files:
              print(f"Processing: {pdf_file}")
              pdf_result = {"file": pdf_file, "status": "pending", "is_clean": False}
              
              try:
                  # Prepare file for upload
                  with open(pdf_file, "rb") as file_handle:
                      files = {"file": (pdf_file.split("/")[-1], file_handle)}
                      data = {"environment_id": ENVIRONMENT_ID}
                      
                      # Submit file for analysis
                      for attempt in range(MAX_RETRIES):
                          try:
                              submission = requests.post(SUBMIT_URL, headers=HEADERS, files=files, data=data)
                              submission.raise_for_status()
                              break
                          except requests.RequestException as e:
                              if attempt == MAX_RETRIES - 1:
                                  raise
                              print(f"Submission attempt {attempt+1} failed: {e}")
                              time.sleep(5)
                      
                      # Process submission response
                      response_data = submission.json()
                      if not response_data.get("job_id"):
                          raise Exception(f"No job_id in response: {response_data}")
                      
                      job_id = response_data["job_id"]
                      sha256 = response_data.get("sha256", "")
                      pdf_result["job_id"] = job_id
                      pdf_result["sha256"] = sha256
                      
                      # Poll for results
                      poll_url = f"{API_BASE}/report/{job_id}/summary"
                      for poll_attempt in range(MAX_POLL_ATTEMPTS):
                          poll_response = requests.get(poll_url, headers=HEADERS)
                          poll_response.raise_for_status()
                          poll_data = poll_response.json()
                          
                          state = poll_data.get("state", "")
                          if state == "SUCCESS":
                              # Extract results
                              verdict = poll_data.get("verdict", "unknown")
                              threat_score = poll_data.get("threat_score", 0)
                              pdf_result["verdict"] = verdict
                              pdf_result["threat_score"] = threat_score
                              pdf_result["status"] = "completed"
                              pdf_result["is_clean"] = verdict == "no threat"
                              
                              # Get behavioral signatures if available
                              signatures = poll_data.get("signatures", [])
                              pdf_result["signatures"] = signatures
                              
                              # Generate result URL
                              if sha256:
                                  pdf_result["result_url"] = f"https://www.hybrid-analysis.com/sample/{sha256}"
                              
                              break
                          elif state in ["ERROR", "FAILED"]:
                              pdf_result["status"] = "failed"
                              pdf_result["error"] = poll_data.get("error", "Unknown error")
                              break
                          
                          # Still processing
                          print(f"Scan in progress. Current state: {state}. Attempt {poll_attempt+1}/{MAX_POLL_ATTEMPTS}")
                          time.sleep(POLL_INTERVAL)
                      
                      # Check if we hit the polling limit
                      if pdf_result["status"] == "pending":
                          pdf_result["status"] = "timeout"
                          pdf_result["error"] = "Analysis timed out"
              except Exception as e:
                  pdf_result["status"] = "error"
                  pdf_result["error"] = str(e)
                  print(f"Error processing {pdf_file}: {e}")
              
              # Add result to collection
              results.append(pdf_result)
              
          # Save results to file
          with open("scan_results.json", "w") as f:
              json.dump(results, f, indent=2)
          
          # Summary for GitHub Actions
          clean_files = [r["file"] for r in results if r["is_clean"]]
          malicious_files = [r for r in results if r["status"] == "completed" and not r["is_clean"]]
          failed_files = [r for r in results if r["status"] in ["error", "failed", "timeout"]]
          
          print(f"\nScan Summary:")
          print(f"- Clean files: {len(clean_files)}")
          print(f"- Malicious files: {len(malicious_files)}")
          print(f"- Failed scans: {len(failed_files)}")
          
          sys.exit(0)
          EOF
      
      - name: Process scan results
        id: scan-results
        run: |
          echo "Processing scan results..."
          python - <<'EOF'
          import json
          import os

          # Load scan results
          with open("scan_results.json", "r") as f:
              results = json.load(f)
          
          # Filter clean PDFs
          clean_pdfs = [r["file"] for r in results if r["is_clean"]]
          clean_pdfs_json = json.dumps(clean_pdfs)
          
          # Output for next job
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"clean_pdfs={clean_pdfs_json}\n")
          
          # Create issues for malicious files
          malicious_files = [r for r in results if r["status"] == "completed" and not r["is_clean"]]
          for file in malicious_files:
              issue_title = f"ðŸš¨ Security threat detected in {file['file']}"
              
              # Format threat details
              threat_details = [
                  f"- **File**: {file['file']}",
                  f"- **Verdict**: {file['verdict']}",
                  f"- **Threat Score**: {file['threat_score']}",
              ]
              
              if "signatures" in file and file["signatures"]:
                  threat_details.append("- **Behavioral Signatures**:")
                  for sig in file["signatures"][:10]:  # Limit to top 10 signatures
                      threat_details.append(f"  - {sig}")
              
              if "result_url" in file:
                  threat_details.append(f"- **Detailed Analysis**: [View on Hybrid Analysis]({file['result_url']})")
              
              issue_body = "## Security Scan Results\n\n" + "\n".join(threat_details)
              
              # Create the issue
              with open(f"issue_{file['file'].replace('/', '_')}.txt", "w") as f:
                  f.write(f"{issue_title}\n\n{issue_body}")
          
          # Create issues for failed scans
          failed_files = [r for r in results if r["status"] in ["error", "failed", "timeout"]]
          for file in failed_files:
              issue_title = f"âš ï¸ Security scan failed for {file['file']}"
              
              # Format error details
              error_details = [
                  f"- **File**: {file['file']}",
                  f"- **Status**: {file['status']}",
                  f"- **Error**: {file.get('error', 'Unknown error')}"
              ]
              
              issue_body = "## Security Scan Failure\n\n" + "\n".join(error_details)
              
              # Create the issue
              with open(f"issue_{file['file'].replace('/', '_')}.txt", "w") as f:
                  f.write(f"{issue_title}\n\n{issue_body}")
          EOF
      
      - name: Create GitHub issues for threats and failures
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.REPO_ACCESS_TOKEN }}
        run: |
          for issue_file in issue_*.txt; do
            if [ -f "$issue_file" ]; then
              TITLE=$(head -n 1 "$issue_file")
              BODY=$(tail -n +3 "$issue_file")
              gh issue create --title "$TITLE" --body "$BODY" || echo "Failed to create issue"
            fi
          done
          
      - name: Upload scan results as artifact
        uses: actions/upload-artifact@v4
        with:
          name: scan-results
          path: scan_results.json
          retention-days: 7

  gemini-conversion:
    name: Convert PDFs to Markdown with Gemini
    needs: [detect-pdfs, hybrid-analysis-scan]
    if: needs.hybrid-analysis-scan.outputs.clean_pdfs != '[]'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-generativeai PyPDF2 requests
      
      - name: Get AI prompt version
        id: get-prompt-version
        run: |
          PROMPT_FILE="AI_PROMPT_MARKDOWN_CONVERT.md"
          if [ -f "$PROMPT_FILE" ]; then
            # Get the latest commit message for the prompt file
            PROMPT_VERSION=$(git log -1 --pretty=format:"%s" -- "$PROMPT_FILE" | grep -o "V[0-9]\+\.[0-9]\+" || echo "V1.0")
            echo "prompt_version=$PROMPT_VERSION" >> $GITHUB_OUTPUT
            echo "Found AI prompt version: $PROMPT_VERSION"
          else
            echo "prompt_version=V1.0" >> $GITHUB_OUTPUT
            echo "AI prompt file not found, using default version V1.0"
          fi
      
      - name: Convert clean PDFs to Markdown
        id: convert-pdfs
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          CLEAN_PDFS: ${{ needs.hybrid-analysis-scan.outputs.clean_pdfs }}
          PROMPT_VERSION: ${{ steps.get-prompt-version.outputs.prompt_version }}
        run: |
          echo "Converting clean PDFs to Markdown with Gemini..."
          python - <<'EOF'
          import os
          import json
          import base64
          import google.generativeai as genai
          from PyPDF2 import PdfReader
          import time
          
          # Set up Gemini API
          genai.configure(api_key=os.environ["GEMINI_API_KEY"])
          
          # Load prompt template
          prompt_file = "AI_PROMPT_MARKDOWN_CONVERT.md"
          if os.path.exists(prompt_file):
              with open(prompt_file, "r") as f:
                  prompt_template = f.read()
          else:
              prompt_template = "Please convert this PDF to markdown format while preserving the structure, headings, tables and bullet points."
          
          # Load clean PDFs list
          clean_pdfs = json.loads(os.environ["CLEAN_PDFS"])
          prompt_version = os.environ["PROMPT_VERSION"]
          
          # Models to try in order
          models = ["gemini-2.0-flash", "gemini-2.0-flash-lite"]
          
          # Process each PDF
          results = []
          for pdf_file in clean_pdfs:
              print(f"Converting {pdf_file} to Markdown...")
              conversion_result = {"file": pdf_file, "status": "pending", "model_used": ""}
              
              try:
                  # Extract text from PDF
                  reader = PdfReader(pdf_file)
                  pdf_text = ""
                  for page in reader.pages:
                      pdf_text += page.extract_text() + "\n\n"
                  
                  # Determine output path
                  input_parts = pdf_file.split("/")
                  filename = input_parts[-1].replace(".pdf", ".md")
                  
                  # Create corresponding Markdown directory structure
                  year_dir = ""
                  if len(input_parts) > 2:
                      # Check if any part looks like a year (4 digits)
                      for part in input_parts:
                          if part.isdigit() and len(part) == 4:
                              year_dir = part
                              break
                  
                  if year_dir:
                      output_dir = f"Markdown Conversions/{year_dir}"
                  else:
                      output_dir = "Markdown Conversions"
                  
                  # Create directory if it doesn't exist
                  os.makedirs(output_dir, exist_ok=True)
                  output_file = f"{output_dir}/{filename}"
                  
                  # Try models in sequence
                  converted_text = None
                  used_model = ""
                  
                  for model_name in models:
                      try:
                          print(f"Attempting conversion with {model_name}...")
                          
                          # Configure model
                          model = genai.GenerativeModel(model_name)
                          
                          # Generate response
                          response = model.generate_content(
                              f"{prompt_template}\n\nPDF Content:\n{pdf_text[:20000]}"  # Limit to avoid token limits
                          )
                          
                          if response.text:
                              converted_text = response.text
                              used_model = model_name
                              print(f"Conversion successful with {model_name}")
                              break
                          
                      except Exception as model_error:
                          print(f"Error with {model_name}: {model_error}")
                          time.sleep(2)  # Brief pause before trying next model
                  
                  if converted_text:
                      # Save converted text to file
                      with open(output_file, "w") as f:
                          f.write(converted_text)
                      
                      conversion_result["status"] = "success"
                      conversion_result["model_used"] = used_model
                      conversion_result["output_file"] = output_file
                      print(f"Saved Markdown to {output_file}")
                  else:
                      conversion_result["status"] = "failed"
                      conversion_result["error"] = "All models failed to convert the PDF"
              
              except Exception as e:
                  conversion_result["status"] = "error"
                  conversion_result["error"] = str(e)
                  print(f"Error processing {pdf_file}: {e}")
              
              results.append(conversion_result)
          
          # Save results for commit step
          with open("conversion_results.json", "w") as f:
              json.dump(results, f, indent=2)
          
          # Summary
          successful = [r for r in results if r["status"] == "success"]
          failed = [r for r in results if r["status"] != "success"]
          
          print(f"\nConversion Summary:")
          print(f"- Successfully converted: {len(successful)}")
          print(f"- Failed conversions: {len(failed)}")
          EOF

      - name: Commit converted Markdown files
        env:
          GITHUB_TOKEN: ${{ secrets.REPO_ACCESS_TOKEN }}
          PROMPT_VERSION: ${{ steps.get-prompt-version.outputs.prompt_version }}
        run: |
          echo "Committing converted Markdown files..."
          
          # Get conversion results
          if [ ! -f "conversion_results.json" ]; then
            echo "No conversion results found"
            exit 0
          fi
          
          # Process each successful conversion
          python - <<'EOF'
          import json
          import os
          import subprocess
          
          # Load conversion results
          with open("conversion_results.json", "r") as f:
              results = json.load(f)
          
          # Process each successful conversion
          for result in results:
              if result["status"] == "success":
                  output_file = result["output_file"]
                  model_used = result["model_used"]
                  prompt_version = os.environ["PROMPT_VERSION"]
                  
                  # Commit message
                  commit_msg = f"Convert {result['file']} to Markdown\n\nAI Prompt {prompt_version} Model {model_used}"
                  
                  # Add and commit the file
                  subprocess.run(["git", "add", output_file])
                  subprocess.run(["git", "config", "user.name", "GitHub Actions"])
                  subprocess.run(["git", "config", "user.email", "actions@github.com"])
                  subprocess.run(["git", "commit", "-m", commit_msg])
                  
                  print(f"Committed {output_file} with message: {commit_msg}")
          EOF
          
          # Push changes if there are any commits
          if git log origin/$(git branch --show-current)..HEAD | grep .; then
            git push
            echo "Pushed conversion commits to repository"
          else
            echo "No new commits to push"
          fi
