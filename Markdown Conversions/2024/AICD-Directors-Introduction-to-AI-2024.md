# A Director's Introduction to AI

## Table of Contents
- [A JOINT PUBLICATION BY](#a-joint-publication-by)
- [CHAPTER 1: AI AND THE RELEVANCE FOR DIRECTORS](#chapter-1-ai-and-the-relevance-for-directors)
- [CHAPTER 2: AI OPPORTUNITIES AND RISKS](#chapter-2-ai-opportunities-and-risks)
- [CHAPTER 3: CURRENT OBLIGATIONS AND THE EVOLVING REGULATORY LANDSCAPE](#chapter-3-current-obligations-and-the-evolving-regulatory-landscape)
- [GO TO CONTENTS](#go-to-contents)
- [PAGE 2](#page-2)
- [Contents](#contents)
- [How to use this guide](#how-to-use-this-guide)
- [Resource purpose, audience & structure](#resource-purpose-audience--structure)
- [Executive summary](#executive-summary)
- [Chapter 1: AI and the relevance for directors](#chapter-1-ai-and-the-relevance-for-directors-1)
- [1.1 What is AI?](#11-what-is-ai)
- [1.2 How and why is AI being used by organisations?](#12-how-and-why-is-ai-being-used-by-organisations)
- [Chapter 2: AI opportunities and risks](#chapter-2-ai-opportunities-and-risks-1)
- [2.1 AI opportunities](#21-ai-opportunities)
- [2.2 AI harms](#22-ai-harms)
- [2.3 Key sources of AI risks and harms](#23-key-sources-of-ai-risks-and-harms)
- [2.4 Perceptions of AI risk amongst corporate leaders](#24-perceptions-of-ai-risk-amongst-corporate-leaders)
- [Chapter 3: Current obligations and the evolving regulatory landscape](#chapter-3-current-obligations-and-the-evolving-regulatory-landscape-1)
- [3.1 Current legal obligations in relation to the use of AI](#31-current-legal-obligations-in-relation-to-the-use-of-ai)
- [3.2 The evolving regulatory landscape](#32-the-evolving-regulatory-landscape)
- [3.3 Safe and responsible AI principles](#33-safe-and-responsible-ai-principles)
- [Where to from here? Governance implications](#where-to-from-here-governance-implications)
- [Acknowledgements](#acknowledgements)
- [ABOUT AICD](#about-aicd)
- [ABOUT HTI](#about-hti)
- [DISCLAIMER](#disclaimer)
- [Copyright](#copyright)

A JOINT PUBLICATION BY

Human
Technology
Institute

A Director’s
Introduction
to AI

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 2

Contents

How to use this guide

Resource purpose, audience & structure

Executive summary

Chapter 1:
AI and the relevance for directors

1.1 What is AI?

1.2 How and why is AI being used by
organisations?

Chapter 2:
AI opportunities and risks

2.1 AI opportunities

2.2 AI harms

2.3 Key sources of AI risks and harms

2.4 Perceptions of AI risk amongst
corporate leaders

Chapter 3:
Current obligations and the evolving
regulatory landscape

3.1 Current legal obligations in relation to the use of AI

3.2 The evolving regulatory landscape

3.3 Safe and responsible AI principles

Where to from here?
Governance implications

Acknowledgements

3

4

5

6

7

9

11

12

14

18

21

22

23

27

32

33

34

TITLE BASELINEBODY COPYHumanTechnologyInstitute

How to use
this guide

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 3

Having considered all the boards on
which you serve, select what applies to you:

What we
suggest you read

I know about ChatGPT, but I don’t know any other types of AI

I am not clear how AI is different to other technologies

I am unsure about the key legal obligations applying to AI use

I am not clear about the key risks or opportunities arising from AI

I do not know the underlying principles of safe and responsible AI

I understand the difference between General AI and Narrow AI

I understand how AI is different to other technologies, but am unclear how this
impacts governance

I am unsure about where AI is used within my organisation

I am unsure about what questions to ask management about the governance
and use of AI and how to assess the quality of management’s responses

I am a director of a SME or NFP and do not know how to implement AI governance

A Director's
Introduction to AI

A Director's Guide to
AI Governance

AI Governance
Checklist for SME and
NFP Directors

TITLE BASELINEBODY COPYHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 4

Resource purpose,
audience & structure

This resource is intended to introduce directors to key AI concepts, and is structured into three chapters:

* Chapter 1 provides directors with an introduction to what AI is, how it is being used and its relevance for directors.

* Chapter 2 outlines the key opportunities and risks of AI use.

* Chapter 3 examines current regulatory obligations related to AI systems and the shifting regulatory environment
locally and internationally.

It is not intended to ‘cover the field’, but to develop a foundational understanding of AI governance.

The resource lays the foundation for directors to apply AI governance principles. This is set out in Part 2 of this series,
‘A Director’s Guide to AI Governance.’

TITLE BASELINEBODY COPYHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 5

Executive summary

There are two main types of AI systems: (1)
General AI systems (which include Generative AI
such as ChatGPT) and (2) Narrow AI systems.

General AI and Narrow AI systems are subject to
different risks and present different governance
challenges. Both types of AI require additional
consideration and oversight from management
and directors

Managing AI systems can be particularly
challenging because of their sophisticated pattern
recognition capabilities, which operate at a large
scale and pull from vast datasets to generate
complex outputs.

AI use within an organisation may not be obvious,
which compounds the governance challenge.

Increasingly, AI is being deployed in core
organisational functions such as strategy,
corporate finance and risk. This trend is likely to
continue, increasing the need for boards to
implement safe and responsible AI governance.

Directors are ultimately responsible for the
oversight of risk management throughout the
organisation. This includes risk arising from AI.

Existing legal obligations in the areas of privacy,
consumer protection, intellectual property, cyber
security, anti-discrimination, duty of care and
work, health and safety continue to apply, and will
be relevant to AI use.

The regulatory landscape is evolving rapidly. While
regulatory approaches differ, a common set of
safe and responsible AI principles underpin
reforms locally and internationally.

TITLE BASELINEBODY COPYHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 6

CHAPTER 1:
AI and the relevance for directors

1.1 WHAT IS AI?

1.1.1 HOW IS AI DIFFERENT FROM OTHER
TECHNOLOGY?

1.1.2 DIFFERENT TYPES OF AI

1.1.3 HOW DO I KNOW WHEN AI IS BEING
USED IN MY ORGANISATION?

1.2 HOW AND WHY IS AI BEING USED BY
ORGANISATIONS?

7

7

8

9

9

TITLE BASELINEBODY COPYHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 7

KEY POINTS:

1.1 WHAT IS AI?

* There are two main types of AI systems: General
AI (or General Purpose AI) and Narrow AI
systems. They are subject to different risks and
present different governance challenges.

* Managing AI systems can be particularly

challenging because of their sophisticated
pattern recognition capabilities, which operate
at a large scale and pull from vast datasets to
generate complex outputs. This can make their
decisions difficult to explain.

* AI use within an organisation may

not be obvious, which compounds the
governance challenge.

* Increasingly, AI is being deployed in core
organisational functions such as strategy,
corporate finance and risk. This trend is likely
to continue, increasing the need for boards to
implement safe and responsible AI governance.

The definition of AI adopted by the International
Organisation for Standardization and the International
Electrotechnical Commission ISO/IEC 22989 is:

An engineered system that generates outputs such as
content, forecasts, recommendations or decisions for a
given set of human-defined objectives.

1.1.1 How is AI different from
other technology?

AI is a special form of digital software that is particularly
good at predicting outputs, optimising, classifying,
inferring missing data, and generating new data.

AI systems can often outperform traditional software,
and as a result offer significant productivity, efficiency
and customer experience benefits.

AI is also more versatile and scalable than traditional
software because it can be replicated and adapted to
new contexts at a relatively low cost. As a result of these
advantages, AI is increasingly being deployed across
organisational teams and functions.

However, the differences between traditional
software systems and AI systems also impacts
governance approaches.

Traditional software systems are built from explicit
rules coded by developers, such that their behaviour is
inherently more predictable and understandable (even if
the software itself is complex).

By contrast, AI systems are often created by defining an
objective and using historical data to create an AI model
that may rely on billions of inferred connections between
data points to achieve its objective. This process means
that it can be extremely challenging to replicate,
explain or test an AI system’s output.

BOX 1: The role of data in AI systems

Data is the foundation of AI systems. Data, including
personal information, is collected and used to train
AI systems. It is both an input and an output of a
deployed AI system.

The selection of data, particularly its quality,
quantity, and representativeness, will significantly
affect the performance of AI systems.

Through the ongoing collection of data and feedback
loops, the accuracy and efficiency of AI systems
should improve over time.

TITLE BASELINEBODY COPYFOOTERHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 8

BOX 2: What kinds of systems are usefully defined as AI?

1.1.2 Different types of AI

* Machine learning: a broad set of models that have been trained on pre-existing
data to produce useful outputs on new data.
* Expert systems: systems that use a knowledge base, inference engine and logic to
mimic how humans make decisions.

Box 2 provides a non-exhaustive list of systems that meet the definition of AI above.

General AI (or General Purpose AI) and Narrow AI are two sub-categories of AI (see
Table 1).

* Natural language systems: models that can understand and use natural
language and speech for tasks such as summarisation, translation, or
content moderation.

* Facial recognition technologies: systems that verify a person, identify someone,
or analyse personal characteristics using facial data drawn from photos or video.

* Recommender systems: systems that suggest products, services or information
to a user based on user preferences, characteristics, or behaviour.

* Automated decision-making systems: systems that use data to classify, analyse
and make decisions that affect people with little or no human intervention.

* Robotic process automation: systems that imitate human actions to automate
routine tasks through existing digital interfaces.

* Virtual agents and chatbots: digital systems that engage with customers or
employees via text or speech.

* Generative AI: systems that produce code, text, music, or images based on text or
other inputs.

* AI-powered robotics: physical systems that use computer vision and machine
learning models to move and execute tasks in dynamic environments.

TABLE 1: Key differences between General AI and Narrow AI

Type of AI system Description1

Examples

General AI (or General
Purpose AI)

An AI system that can be used
for a broad range of tasks,
both intended and unintended
by developers. This includes
Generative AI.

Text generation (i.e. GPT-4,
Gemini), image generation
(i.e. DALL.E, Midjourney),
programming code generation
(i.e. Codex).

Narrow AI

An AI system trained to
deliver outputs for specialised,
constrained tasks and uses to
address a specific problem.

Search engines (i.e. Google,
Bing), facial recognition (i.e.
Apple Face ID), recommender
systems (i.e. Amazon, Spotify,
Netflix).

1 ISO, 2022. ISO-IEC-22989 Artificial intelligence concepts and terminology.

As discussed further in Chapter 2, General AI (including Generative AI) and Narrow AI
present slightly different governance challenges (see Box 9).

TITLE BASELINEBODY COPYHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 9

1.1.3 How do I know when AI is being used in my organisation?

1.2 HOW AND WHY IS AI BEING USED BY ORGANISATIONS?

AI use is not always obvious. This makes its use more difficult to govern. Box 3 sets out
terms that may indicate that AI systems are in use within an organisation.

As AI advances rapidly, corporate leaders would be well-served to take a broad view of
what constitutes an AI system within their organisation.

AI is rapidly becoming an essential part of how organisations operate. Research from
Human Technology Institute (HTI) conducted with business leaders and directors in
2023 found that almost two-thirds of Australian organisations are already using, or
actively planning to use AI systems to support a wide variety of functions.

Organisations are introducing AI systems to secure a range of benefits, including:

BOX 3: Key terms to listen out for to identify potential AI use within
your organisation

The use of AI by organisations is not always clear to executives and directors. In
addition to the kinds of systems listed in Box 2, common terms to listen for which
may indicate the use of AI and warrant further investigation include:

* Model or algorithm (e.g. a specialised piece of software designed to provide a
recommendation, optimise a system, or prioritise an action).

* Training data (e.g. data used to train or fine-tune an AI algorithm).

* Data analytics (e.g. a set of data transformations to classify consumer profiles).

* Predictive analytics (e.g. using data to predict future trends or events).

* Prescriptive analytics (e.g. analysing data to identify the optimal course
of action).

* Process automation (e.g. the use of robotic process automation to perform
repetitive tasks).

* Automated decision-making (e.g. the use of a set of rules or a self-learning
algorithm to make a decision, such as providing a risk classification or approving
a further action).

* reducing costs;

* enhancing productivity;

* improving customer experience; and

* delivering new business growth.

HTI’s data indicates that non-executive directors tend to place more focus on the
opportunity for AI systems to serve customers better, while managers tend to see
greater value in deploying AI systems to achieve process efficiencies (Figure 1).

FIGURE 1: Top expected benefits of AI use by Business Leaders (BL) and Non-
executive Directors (NED) surveyed by HTI in 2023

TITLE BASELINEBODY COPY61.759.553.975.051.175.70%10%20%30%40%50%60%70%80%(NED)(BL)Internal processHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 10

While Narrow AI systems have traditionally been the domain of data analytics teams, cyber security systems or other
back-office functions, the rising capabilities and flexibility of AI systems mean they are increasingly being used in
ways that touch stakeholders directly.

AI systems are undergoing significant changes in their application. Three of the top five priority areas for AI system
use directly impact consumers or employees, including customer service, marketing and sales, and human resources.2

AI is becoming increasingly used in three key areas:

1

2

3

IMPROVING THE CUSTOMER AND
EMPLOYEE EXPERIENCE

INCORPORATION INTO NEW PRODUCTS AND
SERVICES THROUGHOUT THE VALUE CHAIN

INCORPORATION INTO CORE
BUSINESS FUNCTIONS

AI is being used to extend and augment the reach
and output of employees in a way that can improve
the customer experience and reduce the drudgery
of mundane tasks (thereby freeing up employees for
higher value-add work). We detail some of the benefits
of AI use in Chapter 2 (section 2.1). For example,
Telstra is using Generative AI systems to support
frontline teams and answer complex customer queries,
while an AI-driven dashboard in NSW hospital
emergency rooms helps doctors identify patients at a
high risk of sepsis.

AI is being bundled into products and services
that organisations procure through technology
partners. This means it is often used by employees
and across supply chains in ways that are often not
fully visible. For example, a February 2024 survey of
1,000 office workers commissioned by Salesforce
found that 53 per cent of Australian professionals are
actively using or experimenting with Generative AI at
work. Not all of this employee use of AI is disclosed
(known as ‘Shadow IT’ or ‘shadow AI use’(see Box 3 in
Section 1.3 of A Director's Guide to AI Governance)),
which creates risks and governance challenges.

AI systems are being applied closer to the ‘core’ of
organisations, with some of the most rapid growth
in strategy, corporate finance, and risk functions.
For example, a 2024 NVIDIA survey found that risk
management was the second-highest current use and
top investment domain for AI systems in the financial
services sector.

2 Lauren Solomon and Nicholas Davis, The State of AI Governance in Australia (HTI Report, 2023).

TITLE BASELINEBODY COPYHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 11

CHAPTER 2:
AI opportunities and risks

2.1 AI OPPORTUNITIES

2.2 AI HARMS

2.2.1 HARM TO INDIVIDUALS AND
THE IMPORTANCE OF VULNERABLE
COMMUNITIES

2.2.2 HARM TO SOCIETY

2.2.3 HARM TO ORGANISATIONS

12

14

15

16

17

2.3 KEY SOURCES OF AI RISKS AND HARMS

18

2.4 PERCEPTIONS OF AI RISK AMONGST
CORPORATE LEADERS

21

TITLE BASELINEBODY COPYHumanTechnologyInstitute

KEY POINTS:

* AI use can produce benefits and opportunities
as well as risks and harms.

* Key benefits of using AI systems include
increased productivity, quality improvement,
new products and services, and an improved
customer and employee experience.

* Many of the potential harms to consumers or
employees from AI system misuse or failure
are foreseeable and capable of mitigation.

* Without appropriate controls, AI systems tend
to negatively and disproportionately affect
vulnerable and marginalised populations.
Organisations need to ensure that processes
are in place to identify and prevent
these harms.

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 12

2.1 AI OPPORTUNITIES

AI systems promise a range of significant benefits for organisations. These include:

INCREASED EFFICIENCY AND PRODUCTIVITY
Some AI systems can reduce the time burden
of administrative tasks through new forms of
automation. Others allow employees to expand
their output and add additional value, helping
teams to analyse trends, summarise existing
content, and generate new content. A 2023
experiment designed by MIT Sloan found that
when Generative AI was particularly suited to
a task, it could enhance worker productivity by
approximately 40 per cent.

REDUCTION IN ERROR AND QUALITY
IMPROVEMENTS

While AI systems are extremely prone to errors
when input data or queries fall outside their
core competency, for well-known mechanical
or repetitive tasks, particularly those involving
pattern recognition, they can perform
significantly better than other approaches,
including human experts.

NEW PRODUCTS AND SERVICES
Both Narrow and General AI systems can support
organisations with a range of innovation-related
tasks, including helping organisations identify,
predict demand, design, prototype, and test new
products and services.

IMPROVED CUSTOMER EXPERIENCE
Thanks to their ability to engage in natural
language and scale digitally, General AI systems
are helping to reduce customer wait times,
improve accessibility of existing information, and
personalise the customer experience.

IMPROVED EMPLOYEE EXPERIENCE
AI can reduce the time and cost spent by
employees on administrative tasks to allow focus
on value-add work and innovation. Some AI
(such as Generative AI) can also guide workers
through more complex tasks and can assist
in problem-solving.

TITLE BASELINEBODY COPYFOOTERHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 13

Capitalising on the opportunities above requires an investment of time and resources.
Successful implementation of AI also relies on high levels of trust and engagement
from customers and employees, supporting infrastructure (including effective data
governance), and users with the necessary skills and training.

Conversely, inaction or failing to seize the opportunities offered by AI can present
significant risks for organisations (see section 2.2.3). Early adopters of AI systems
have gained, and are continuing to gain, competitive advantages.3 For example, AI-
driven search, pioneered by Google, signficantly impacted advertising strategies, and
AI systems were central to the disruption of the taxi industry by rideshare companies.

Sectoral differences are also emerging in AI adoption and use. In Australia, research
indicates that aerospace, defence and security, mining, energy and resources,
agriculture, health, and transport were the top industries serviced by AI firms in 2021.4
Globally, the industries leading the adoption of AI technology in 2023 were technology,
financial services, health, transport and education.5

BOX 4: Potential economic impact of Generative AI on the
Australian economy

In July 2023, Microsoft and the Tech Council of Australia issued a report on the
economic impact of Generative AI on Australia.

The report found that Generative AI could add between $45 to $115 billion in GDP
to the Australian economy annually.

The majority (70 per cent) of these gains are estimated to come from productivity
improvements - it is estimated that Generative AI has the potential to automate or
augment 44 per cent of an average worker's tasks. The remainder comes from new
jobs and new products, services and businesses, with the biggest opportunities in
healthcare, manufacturing, retail and professional and financial services.

3 McKinsey, The state of AI in 2022 — and a half decade in review (Report, December 2022).

4 Austrade, The 2021 Australian Artificial Intelligence Export Survey (Report, 2021).

5 John Mangan, Australia’s AI Imperative: The economic impact of artificial intelligence and what’s needed to further its growth (Kingston AI Group Report, 2024).

TITLE BASELINEBODY COPYHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 14

2.2 AI HARMS

The specific characteristics of AI systems that set them apart from traditional software also mean that they
can amplify existing harms while creating new ones that may affect individuals, organisations and/or society.
Table 2 summarises these potential harms.

TABLE 2: Potential harms to individuals, organisations and society from AI systems

Harm to individuals
(consumers, employees,
members of the public)

Harm to
organisations

Harm to
society

* Physical, psychological, economic, or reputational harm
* Misleading advice or information
* Violation of civil liberties
* Breach of privacy
* Unlawful discrimination and exclusion
* Unfair treatment

* Commercial losses
* Reputational damage
* Regulatory sanctions

* Job displacement
* Economic inequality
* Large-scale damage to public health, infrastructure or
essential services

* Environmental damage
* Social and political manipulation
* Discrimination and oppression of minority groups

TITLE BASELINEBODY COPYFOOTERHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 15

2.2.1 Harm to individuals and the importance of
vulnerable communities

As Chapter 3 details, there are a wealth of existing laws relevant to an organisation’s
use of AI. Some of these may result in liability for organisations – and directors
personally – if individuals are harmed as a result of AI systems.

Research indicates that AI harms tend to disproportionately affect vulnerable and
marginalised communities. The reasons for this are complex, but are often driven by
systemic biases that exist in the data used to train AI models, the design, engineering
and modelling processes, and the contexts in which AI models are ultimately deployed
by decision makers.6

The under representation of women or people of colour in data can lead to decreased
accuracy of AI systems, such as facial recognition technologies or computer-aided
diagnosis systems, including medical image interpretation.

Directors should be mindful of the impact of AI use on vulnerable and marginalised
individuals, and consider ways to mitigate this (see practical steps in A Director’s
Guide to AI Governance).

BOX 5: The Risk of Bias

Bias is one of the most well-documented concerns related to AI systems. This issue
arises because of the potential for AI systems to inherit and amplify biases present
in real-world data.

AI systems are also prone to bias due to their reliance on historical data for
training. Bias may emerge from:

* pre-existing biases present in the real world;

* the use of non-representative data sets; and

* the selection of algorithm approaches or objective functions that intrinsically
embed the bias of the development team.

Directors should be vigilant that the use of an AI system may create outcomes that
are unlawful and discriminatory and disadvantage individuals or groups based on
protected characteristics such as their age, race, sex, or disability.

Addressing bias in AI systems is not straightforward. Technical solutions alone are
often insufficient to fully rectify the biases embedded within real-world data. The
Australian Human Rights Commission’s technical paper on addressing algorithmic
bias provides a comprehensive examination of this issue, highlighting the
limitations of relying solely on technological fixes to address biases in AI systems.

In light of this, directors should be aware of, and champion approaches that
combine technical, operational, and governance practices to help mitigate
the risk of bias and ensure AI systems are developed and deployed in a fair and
human-centred manner.

6 Reva Schwartz et al, Towards a Standard for Identifying and Managing Bias in Artificial Intelligence (NIST Special Publication 1270, 2022).

TITLE BASELINEBODY COPYHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 16

2.2.2 Harm to society

BOX 6: Workforce impact and job displacement

Collective harms that can arise from AI system misuse
or failure include social and political manipulation, new
forms of technological unemployment, and the systemic
oppression or exclusion of minority groups. When used at
scale by those with broad reach (such as governments
and essential service providers) even relatively small
errors or biases in a system can cause large harms when
scaled across groups.

While such society-wide effects are the purview of
government policy, directors should be aware of these
macro-level harms and how issues such as AI system job
displacement may be viewed by stakeholders.

Research estimates that 300 million full-time equivalent workers are susceptible to automation as a result of AI
systems.7 However, the research finds AI systems are more likely to augment workers by automating some tasks,
but not replace them outright. Further, AI is creating new jobs, bringing opportunities for the retraining and
redeployment of workers.

A World Economic Forum report states that AI is expected to be adopted in 2023-2027 by 75 per cent of
companies surveyed. Despite the workforce transformations that many anticipate being driven by AI, only 25 per
cent of these organisations expect it to create net job losses. More than 50 per cent of organisations expect it to
create net job growth.

As AI transforms the way people work, it also offers the possibility of improving worker satisfaction. A survey
by Microsoft indicates that whilst 49 per cent of people are worried AI will replace their jobs, 70 per cent would
happily delegate work to AI to ease their workloads.

Organisations should engage with employees about the impact of AI on their roles and the potential for AI to
assist worker productivity and efficiency and to provide skills to allow them to gain opportunities for retraining.

7 Jan Hatzius et al, The Potentially Large Effects of Artificial Intelligence on Economic Growth (Briggs/Kodnani), Goldman Sachs (online, 26 March 2023).

TITLE BASELINEBODY COPYFOOTERHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 17

2.2.3 Harm to organisations

BOX 7: Sustainability, ESG and AI

It is important to recognise that there are risks for organisations at two levels:

* risks arising from AI system investment and use; and

* risks arising from underinvestment and a lack of adoption.

AI misuse or system failures can create and amplify a range of commercial,
reputational and regulatory risks to organisations.

AI systems raise risks and harms that may be captured under environmental, social
and governance (ESG) or sustainability frameworks. For example, the training of
Generative AI models can have an environmental impact given the significant
energy and water it requires. The potential of AI to disproportionately impact
vulnerable persons is also a ‘social’ risk (the 'S' within ESG).

Addressing ESG matters will necessarily address some of the risks and harms
of AI systems.

FIGURE 2: Risks to organisations from AI use

In November 2022, AICD partnered with Herbert Smith
Freehills to publish, under the Climate Governance
Initiative (CGI) Australia banner, a ‘Bringing together
ESG’ resource to help boards develop appropriate
governance structures to effectively oversee
sustainability issues.

However, given the specific challenges, harms and opportunities of AI systems,
ESG frameworks alone are not sufficient. There must be broader consideration of AI
systems for their effective governance (see A Director’s Guide to AI Governance).

On the other hand, a lack of investment in AI capabilities also leaves organisations
vulnerable to a range of other risks, such as a lack of competitiveness, higher costs,
lack of new product and service delivery, poorer consumer service, as well as talent
acquisition and retention challenges.

The risks of action and inaction must be carefully weighed by directors alongside the
organisational strategy and the risk appetite of the organisation (discussed further in
A Director’s Guide to AI Governance).

BOX 8: Generative AI and cyber security risks

Generative AI systems are likely to give rise to specific cyber security risks and
undermine existing controls. For example, deepfake AI tools could be used to
generate realistic synthetic media that impersonates individuals for the purposes of
identity theft, fraud or spreading misinformation about a particular organisation.
To mitigate these risks, boards should oversee the strengthening of cyber security
controls, such as data encryption, access controls, employee training and regular
external cyber security audits.

TITLE BASELINEBODY COPYAmplified risks to organisationsCommercialReputationalRegulatoryCommercial losses due to poor or biased AI system performance; adversarial attacksDamage to reputation and loss oftrust due to harmful or unlawful treatment of consumers, employees or citizensBreach of legal obligations that may result in fines, restrictions and require management focusHumanTechnologyInstitute

CHAPTER 1:
AI AND THE RELEVANCE
FOR DIRECTORS

CHAPTER 2:
AI OPPORTUNITIES
AND RISKS

CHAPTER 3:
CURRENT OBLIGATIONS
AND THE EVOLVING
REGULATORY LANDSCAPE

GO TO CONTENTS

PAGE 18

2.3 KEY SOURCES OF AI RISKS AND HARMS

AI risks and harms are created because of the way AI systems perform and behave,
as well as how they might be used. Table 3 outlines some examples of how such
risks arise.

TABLE 3: Key sources of AI risk for organisations

Key sources of AI risk

Examples

AI system failures – where
systems create harm because
they fail to perform as intended

Malicious, misleading, reckless,
or inappropriate use – where
systems are deliberately used
(whether by the organisation or
external parties) in a way which
creates or amplifies risk of harm

* Poor system performance
* Biased system performance
* System fragility or unreliability
* Security failures or vulnerabilities

* Misleading advice
* Misinformation at scale
* Unfair or extractive use
* Opacity and lack of interpretability
* Weaponisation
* AI-powered cyber attacks
* Fraudulent and unlawful use e.g. scams
* Financial market manipulation
* Excessive deployment
* Deployment on vulnerable individuals

Risk management frameworks must identify and mitigate risks of system failures and
misuse – this is discussed further in A Director’s Guide to AI Governance.

Table 4 sets out five characteristics that impact the potential for an AI system to cause
harm. Box 9 shows how these five characteristics create different levels of challenge
across Generative AI (a subset of General AI) and Narrow AI systems.

TABLE 4: Factors that drive harms from system failure, misuse, or
inappropriate use

Factor

Purpose

Context

Data

Technical
architecture

Level of automation

Re