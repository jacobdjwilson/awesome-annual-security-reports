# 2025 Identity Security Landscape

Perspectives on risk and readiness from security leaders.

A Security Matters Research Report by CyberArk

## Table of Contents
- [Executive Overview](#executive-overview)
- [The AI Trifecta: Attacker, Defender and Identity Risk](#the-ai-trifecta-attacker-defender-and-identity-risk)
- [Machine Identities: The Sprawl Awakens](#machine-identities-the-sprawl-awakens)
- [Breaking Silos, Taking Names](#breaking-silos-taking-names)
- [Parting Thoughts](#parting-thoughts)
- [Appendix](#appendix)

## Executive Overview

Welcome to the 2025 Identity Security Landscape! This study wouldn’t be possible without the generous insights from our 2,600 security decision-makers across 20 countries around the globe—a big thank you to our contributors and researchers.

If you scrolled here for the first time, welcome. This report specifically examines cyberattack trends impacting identity across modern IT ecosystems and shares insights on how security professionals can and should prepare.

Our returning readers are well aware that AI is arming both sides of the security battle, helping attackers and defenders alike. But what’s more interesting this year is how the race to adopt AI has inadvertently expanded the attack surface with a surge of machine identities. Welcome to the third dimension of AI: attackers use it to create new threats; defenders use it to defend against them—and businesses incur new identity-centric risks as they embed agentic AI across the enterprise.

On one hand, we’re seeing the most relentless and sophisticated cyberattacks of the modern age, with 9 out of 10 organizations reporting a successful identity-centric breach. Over half (51%) fell victim to phishing and vishing attacks multiple times. At the same time, respondents tell us sanctioned and unsanctioned adoption of AI is adding to cybersecurity risks. Organizations now report that 72% of employees regularly use AI tools on the job—yet 68% of respondents still lack identity security controls for these technologies. Machine identities now outnumber human identities by more than 80 to 1. Some would call this “unprecedented”— we prefer overachiever in the field of firsts.

Machine identities now
outnumber human identities
by more than 80 to 1.

The outlook on the geopolitical front is not much brighter. Last year, the Election Cyber Interference Threat Research Report warned that state-sponsored attackers would step up the use of AI in their disruptive operations against the U.S. and its allies. Nation states aren’t just sponsoring these attacks; they’re joining forces with cybercriminal organizations to ramp up cyber espionage and disinformation. They’re hitting businesses, critical infrastructure and even the financial world, including a recent $1.5B crypto heist from ByBit. In December, the U.S. confirmed that Chinese government hackers gained remote access to the Treasury in what it described as a “major cybersecurity incident.”

AI has captured the world’s imagination. But, as philosopher Paul Virilio once said, “When you invent the ship, you also invent the shipwreck.” The same AI that can protect can also attack. It can detect vulnerabilities—and exploit them.

In the race to adopt AI, organizations are also inadvertently creating a surge of unmanaged and unsecured machine identities that overburdened teams don’t have the visibility to manage. The privileged access of AI agents represents an entirely new threat vector that existing security models aren’t built to handle. To stay resilient in this “overachieving” identity threat landscape, we can’t wait for someone else to take the wheel. We must own our identity risk strategy and modernize our approach so we can adapt, respond and recover.

If you were already buckled up, maybe also bite down. What a time to be alive.

Here’s what you’ll find in this year’s report:

1.  AI’s potential to be an identity-centric threat trifecta.
2.  The shocking surge of machine identities, the scope of human identities with unsecured privileged access and the unique challenges both present for the enterprise.
3.  The emergence of identity silos and how they undermine business resiliency.

Protecting sensitive and confidential data from breaches or leaks is paramount to maintaining trust and operational resiliency. As always, we’ll dig into the data to highlight what’s evolving—and share the steps you can take now to help your organization make the right kind of cybersecurity history.

Sincerely,

Clarence Hinton
Chief Strategy Officer, CyberArk

Clarence Hinton

Chief Strategy Officer

AI has captured the world’s imagination. But, as philosopher

Paul Virilio once said, “When you invent the ship, you also

invent the shipwreck.”

### At a Glance

![Figure 1. Key trends highlighting the impact of AI, machine identity and silos on identity risk (n=2,600). This image summarizes key findings: AI is the #1 risk, with 68% lacking identity security controls for AI and 47% unable to secure shadow AI. The machine identity explosion fuels privilege sprawl, with machine identities vastly outnumbering humans (82:1), 94% reporting an increase in machine identities, and 88% of machine identities having access to sensitive data. Identity silos are overwhelming security leaders, with 70% saying silos are a root cause of risk, 49% lacking complete visibility into cloud entitlements, 94% defining 'privileged users' as human-only, 88% under pressure from insurers for enhanced privilege controls, and 94% saying lack of integration hinders attack detection.]

**AI #1 Risk**
AI is the #1 creator of new identities with privileged and sensitive access in 2025.

**AI IDENTITY RISK IS EVERYWHERE**
- 68% of respondents lack identity security controls for AI.
- 47% cannot secure shadow AI.
- #1 Manipulation and access concerns are the primary roadblocks to AI agent adoption.

**THE MACHINE IDENTITY EXPLOSION FUELS PRIVILEGE SPRAWL**
- 82:1 Machine identities vastly outnumber humans.
- 94% of respondents report an increase in machine identities over the past 3 years.
- 88% of machine identities have access to sensitive data.
- 94% of respondents still define ‘privileged users’ as human-only.
- 88% are under pressure from insurers mandating enhanced privilege controls.

**IDENTITY SILOS ARE OVERWHELMING SECURITY LEADERS**
- 70% of respondents say identity silos are a root cause of cybersecurity risk.
- 49% lack complete visibility into entitlements and permissions across their cloud environments.
- 94% say lack of integration between identity and security tools hinders their ability to detect attacks.

## The AI Trifecta: Attacker, Defender and Identity Risk

In 2025, we’d be hard-pressed to find a place where AI has not relieved humans of manual and repetitive processes. It now regulates our grid, monitors our crops, directs traffic and strengthens our cybersecurity arsenal. Our survey found that 94% of respondents (Figure 2) use AI and LLM processes to enhance their overall identity security strategies. Figure 3 shows that 61% are considering using AI to secure both human and machine identities in the next 12 months. Unfortunately, bad actors have had a head start using AI to make their attacks faster, smarter and harder to stop.

In addition, our report found that AI and LLMs are expected to drive the creation of the most new identities with privileged and sensitive access in 2025. This means that organizations must now secure the AI systems they deploy—and the new identities those systems create. Essentially, we must now manage AI as a weapon that can break into our systems; AI as a defender that secures our systems; and now, AI itself as a system we must secure.

We kick off this year’s report by taking a closer look at how these three dimensions of AI triangulate the pressure on security teams.

### Clunky, error-filled spam—and other things we miss

In the last 12 months, phishing has remained the leading cause of identity-related breaches. What’s changed is the AI-driven scale, sophistication and success rate of these attacks.

Attackers can send AI-generated phishing emails that are highly personalized, context-aware and nearly indistinguishable from legitimate senders. They can use AI to analyze public data, mimic tone and formatting and adapt messaging in real time — making it easier to deceive even security-savvy users. And because AI can automate and coordinate outreach across email, chat and voice channels, social engineering campaigns are more convincing than ever before.

![Figure 2. AI is both a powerful ally and a potential liability (n=2,600). This bar chart shows that 94% of respondents lack identity security controls for AI and LLMs, 72% regularly use AI tools on the job, and 36% report using AI tools that are not fully approved or managed by IT.]
- 94% lack identity security controls for AI and LLMs.
- 72% regularly use AI tools on the job.
- 36% report using AI tools that are not fully approved or managed by IT.

**WHAT WE ASKED**
Which of the following processes is your organization planning to enhance with AI to protect both human and machine identities? (Multi-select question)

![Figure 3. Top processes respondents are considering for securing identities with AI (n=2,600). This bar chart shows the percentage of organizations planning to enhance processes with AI to protect human and machine identities: Integrating AI into identity security systems (61%), Detecting AI-generated synthetic identities (58%), Advanced identity verification (54%), Real-time anomaly detection (52%), Automating auditing and compliance (51%), Predicting identity threats (48%), Strengthening biometrics (43%). 1% are not considering using AI.]
- Integrating AI into identity security systems: 61%
- Detecting AI-generated synthetic identities: 58%
- Advanced identity verification: 54%
- Real-time anomaly detection: 52%
- Automating auditing and compliance: 51%
- Predicting identity threats: 48%
- Strengthening biometrics: 43%
- My organization is not considering using AI to secure identities: 1%

**WHAT WE ASKED**
What are your organization’s primary use cases for AI and LLM applications? (Multi-select question)

![Figure 4. Use cases and LLM applications (n=2,600). This bar chart shows the primary use cases for AI and LLM applications: Advanced data analytics and insights (55%), Chatbots and virtual assistants (51%), Automated customer support solutions (50%), Data transformation and processing (49%), Fraud detection and prevention (48%), Content creation and generation (42%), Enterprise search optimization (39%), Meeting transcription and summarization (38%), Personalized marketing (35%), Code generation (34%). 1% do not use AI or LLM models.]
- Advanced data analytics and insights: 55%
- Chatbots and virtual assistants: 51%
- Automated customer support solutions: 50%
- Data transformation and processing: 49%
- Fraud detection and prevention: 48%
- Content creation and generation: 42%
- Enterprise search optimization: 39%
- Meeting transcription and summarization: 38%
- Personalized marketing: 35%
- Code generation: 34%
- My organization does not use AI or LLM models or applications: 1%

AI-generated phishing then becomes an ultra-effective entry point for attackers who want to harvest credentials, escalate privileges and fast-track the exploitation of vulnerable applications, compromised privileged access and credential-based attacks. Nine out of 10 organizations reported experiencing a successful breach of this nature. Over three-quarters of respondents reported falling prey to successful phishing attacks (including AI-driven deepfake scams) within their organizations—and more than half of these fell victim multiple times.

Case in point: In February, scammers targeted prominent Italian business figures, including Giorgio Armani, using AI to mimic the voice of Guido Crosetto, Italy’s Defense Minister. The fraudsters requested financial assistance under the guise of freeing kidnapped journalists, leading at least one victim to transfer €1 million to a Hong Kong bank account.

### Identity security’s new clutch player

For security teams, AI can reduce response times from hours to seconds. As it has no pesky human needs, it can ceaselessly analyze historical attack patterns, predict what’s next, prioritize vulnerabilities and automatically shut down threats. Security operations centers (SOCs) can use AI to sift through mountains of identity-related threat data in real-time — not to replace human analysts, but to augment them.

AI also handles time-consuming, repetitive tasks and surfaces useful insights, allowing security teams to focus on bigger threats and make smarter, more strategic decisions. When paired with security orchestrations, automation and response (SOAR) systems, this human-AI collaboration can make incident responses more efficient and adaptive. In Figure 4, 55% of respondents say they use AI for advanced analytics and anomaly detection. Respondents cite AI as one of the most impactful tools for reducing identity-related threats in 2025.

AI handles time-consuming, repetitive

tasks and surfaces useful insights, allowing

security teams to focus on bigger threats

and make smarter, more strategic decisions.

### Meet your new sidekick/supervillain

But as AI-driven cybersecurity becomes a frontline defense strategy, securing the AI systems—including their machine identities—becomes just as critical. AI’s reliance on vast amounts of data increases the risk of breaches, misuse and unauthorized access. Figure 5 shows that 82% of respondents know that using AI models opens access to sensitive data and creates cyber risks.

In the wrong hands, AI models can be manipulated into executing database queries, running external API calls or even accessing networked machines. Studies show that attackers are finding new ways to “jailbreak” (manipulate LLMs into secretly extracting and sending users’ personal information, such as names, IDs, email addresses, payment details, etc.) with nearly 100% success rates on various models.

Jailbreaking AI models isn’t just a theoretical exercise—it’s a growing security concern as organizations rush to deploy AI without fully understanding its ramifications. Incidentally, that’s why CyberArk’s new FuzzyAI tool is making waves—it has successfully jailbroken every model it has tested. As an open-source project, now available on GitHub, it can help organizations and researchers systematically identify and fix AI security gaps before attackers exploit them.

![Figure 5. AI adoption is outpacing security controls (n=2,600). This chart shows that 82% say their use of AI models creates sensitive access risks, 68% do not have identity security controls in place for AI and LLMs, and 47% report they cannot secure shadow AI usage in their organization.]
- 82% say their use of AI models creates sensitive access risks.
- 68% do not have identity security controls in place for AI and LLMs.
- 47% report they cannot secure shadow AI usage in their organization.

### Shadow AI: No one approved it. Everyone’s using it.

Enterprises are using multiple approaches when hosting their AI tools, often adopting leading global LLM AI models (such as OpenAI, Google, Amazon Bedrock and Meta AI), coupling public training datasets with proprietary enterprise data to train the AI to solve problems. While 64% say that all of their