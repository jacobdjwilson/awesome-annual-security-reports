# State of Pentesting Report 2025

## Table of Contents
- [Foreword](#foreword)
- [Executive Summary](#executive-summary)
  - [Key Findings](#key-findings)
- [Pentesting Perspectives](#pentesting-perspectives)
- [Top Pentesting Findings](#top-pentesting-findings)
  - [Web applications and APIs](#web-applications-and-apis)
  - [Mobile applications](#mobile-applications)
  - [AI and LLMs](#ai-and-llms)
  - [Severity of findings](#severity-of-findings)
  - [Resolution of findings](#resolution-of-findings)
  - [Time to resolution](#time-to-resolution)
  - [Half-life of findings](#half-life-of-findings)
  - [All together now](#all-together-now)
- [Recommendations from this analysis](#recommendations-from-this-analysis)
- [Research Methodology](#research-methodology)
  - [Pentesting data](#pentesting-data)
  - [Survey sample](#survey-sample)
- [About Cobalt and Cyentia](#about-cobalt-and-cyentia)

## Foreword

Thank you for reading the State of Pentesting Report 2025, our assessment of the results of thousands of pentests conducted via the Cobalt Offensive Security Platform. Looking back at the very first report in this series, published in 2019, it’s remarkable how much the security landscape has changed, and how we’ve changed with it.

Cobalt, the pioneer in Pentesting as a Service, is now at the forefront of testing AI models and applications. We’ve found that AI security is lagging far behind the pace of AI adoption. Our LLM testing finds more vulnerabilities than any other type of test, and only 21% of the highest risk LLM vulnerabilities are resolved.

At the same time, security leaders are unfazed, but perhaps overconfident. While 81% are certain they meet security compliance, pentesting data tells a more complicated story. Although SLAs aim for two-week remediation windows, the real time to resolution often stretches to months or even years. It takes over three months for just half of the most serious issues to be resolved.

Development and security teams have made strides in reducing high-risk vulnerabilities, and the time to resolve these findings dropped by two-thirds over the past decade. These improvements were likely driven by increased adoption of structured pentesting programs over ad hoc testing, and more rigorous security standards during software development.

However, the persistence of unaddressed, exploitable vulnerabilities underscores the need for programmatic approaches that go beyond meeting SLA timelines to ensure true risk reduction.

At Cobalt, we understand the dangers of hidden security vulnerabilities, including ones frequently missed by automated scanners. As our industry evolves alongside growing investment in AI solutions, we continue to innovate. Yet our identity remains unchanged, centered around the expertise of the Cobalt Core, our team of over 450 pentesters.

Within these pages, you’ll find an in-depth examination of pentesting results, and insights about the challenges security teams are facing. We expect these insights to help security leaders guide their organizations towards better offensive security programs, for greater assurance and reduced risk.

Gunter Ollman
Chief Technology Officer | Cobalt

Jason Lamar
SVP of Product | Cobalt

## Executive Summary

Knowledge is power—and in security, that knowledge must come from the right insights.

Security leaders feel confident in their posture, but pentest data tells a more complex story: Critical vulnerabilities often remain unresolved, hidden beneath the surface of automated scans and service-level agreement (SLA) checkboxes. Even as remediation speeds improve, one-third of serious issues still slip through the cracks—and with genAI introducing new, high-impact risks, traditional approaches fall short.

That’s why pentesting is essential. It transforms assumptions into evidence, surface-level confidence into actionable clarity. Structured, expert-led pentesting delivers the knowledge security teams need to understand their true risk—and the power to reduce it.

### Key Findings

-   **THE PERCEPTION AND REALITY OF SECURITY DON’T ALWAYS AGREE**
    -   Most organizations (81%) are quite confident that their security posture is up to snuff. Yet pentesting never fails to reveal hidden vulnerabilities.
    -   Three-quarters of organizations have set SLAs specifying that pentest findings should be fixed in two weeks or less. Few meet this goal.
    -   The median time to resolve (MTTR) stands at 67 days for all pentest findings. That’s five times longer than the two-week SLA set by most organizations.
    -   Less than half (48%) of all findings ever get resolved. That jumps to 69% for the riskiest findings, but that still leaves many open vulnerabilities.

-   **AI IS QUICKLY EMERGING AS A MAJOR SECURITY RISK**
    -   Nearly all firms say they’re integrating genAI into their products; just 66% are actively assessing the security (including pentesting) of these solutions.
    -   32% of all LLM pentest findings are rated high risk. That’s 2.5 times the overall proportion of 13% and the highest level among all types of pentests we conduct.
    -   Only 21% of serious findings from LLM pentests get resolved. That’s understandable given the newness of the tech. But that doesn’t negate the risk.

-   **PROGRESS IS BEING MADE TO REDUCE RISK, BUT THERE’S MUCH MORE TO DO**
    -   94% of firms view pentesting as essential to their program. But evidence suggests many aren’t taking a programmatic approach to offensive security.
    -   In 2017, only 27% of serious pentest findings were resolved. That proportion soon doubled to 55% but has hovered at that level ever since.
    -   In 2024, serious findings were fixed in one-third of the time it took back in 2017 (37 versus 112 days). That’s shaving 75 days off the exposure window!
    -   The largest organizations take over a month longer to resolve serious findings than the smallest firms (61 versus 27 days). Managing risk gets harder as you grow.

## Pentesting Perspectives

Before diving into all the issues Cobalt pentesters identified, let’s review what we learned from our survey of 450 security leaders and practitioners about how penetration tests fit into their security programs.

Let’s start with the most common internal justifications for conducting pentests. The top reason selected by 94% of respondents was that pentests are foundational to ensuring a strong security posture. This captures the assurance role of pentesting and reflects the reality that most breaches don’t occur because the victim had no defenses. Rather, the defenses they had weren’t as solid as they thought.

It’s probably no surprise to learn that most respondents (91%) chose compliance as a major reason why they do pentests. What may surprise some is that even more of them (92%) say pentests are important to their organization’s strategy and senior leadership. Over three-quarters of firms (and 92% of retailers) claim that pentesting improves customer trust.

Let’s keep pulling on the “improves customer trust” thread. We asked participants about the types of security assurance commonly requested by their customers and regulators. Third-party pentest reports were the most common selection, at 59% of respondents. It’s noteworthy that pentests rate higher than vulnerability scans and compliance certifications.

![Figure 1: Why does your organization conduct pentests?]
- FOUNDATIONAL FOR MODERN PROGRAMS TO ENSURE A STRONG SECURITY POSTURE
- IMPORTANT TO OUR ORGANIZATION’S STRATEGY AND SENIOR LEADERSHIP
- CRITICAL FOR MEETING OUR BUSINESS AND COMPLIANCE GOALS
- IMPROVES CUSTOMER TRUST IN OUR SOFTWARE PRODUCTS

![Figure 2: What types of security assurance do your customers or regulators most commonly request to validate your software’s security?]
- 3RD PARTY PENETRATION TEST REPORT
- 3RD PARTY CODE REVIEW
- INTERNAL SECURITY TEST RESULTS
- VULNERABILITY SCAN REPORTS
- COMPLIANCE CERTIFICATION (SOC 2, ISO 27001, ETC)
- NONE OF THE ABOVE

There are several factors that tend to trigger requests to validate third-party software using pentests. Top choices include software that processes sensitive data or is critical to the organization’s mission. Over a third of organizations test all vendor software that gets built into their products, though including those that answered “all of the above” raises that to over 60%.

![Figure 3: What type(s) of commercial software do you require a pentest from vendors?]
- SOFTWARE BUILT INTO OUR PRODUCTS
- SOFTWARE THAT PROCESSES CUSTOMER DATA
- MISSION CRITICAL SOFTWARE FOR OUR ORGANIZATION
- ALL OF THE ABOVE
- SOFTWARE THAT PROCESSES PII

Pentests are also seen as a way to reduce liability for security issues. Per the responses below, that liability is seen at both the personal and corporate levels. Furthermore, a quarter of respondents believe security assurance to be so important that they’ve considered quitting when that obligation isn’t taken seriously enough. Keep these (rather idealistic) responses in mind when we get to the section analyzing the reality of pentest remediation timelines.

![Figure 4: Concerns over liability related to unaddressed security issues]
- IT CAUSES CORPORATE LIABILITY IF EXPLOITABLE VULNERABILITIES REMAIN UNADDRESSED
- I FEEL PERSONAL LIABILITY IN KNOWING EXPLOITABLE VULNERABILITIES ARE UNADDRESSED
- I WORRY ABOUT THE LEGAL REPERCUSSIONS OF UNFIXED EXPLOITABLE VULNERABILITIES
- I’VE CONSIDERED LEAVING MY JOB BECAUSE SECURITY IS NOT TAKEN SERIOUSLY ENOUGH

It’s obvious from the responses above that pentests are viewed as an important part of modern security programs. But how often are they conducted? Just over a quarter of respondents do annual pentests, and another 15% say it’s a semi-annual activity for their firms. That means more than half of organizations conduct pentests more than twice a year, with quarterly being the most common cadence (30%).

![Figure 5: How often does your organization conduct pentests?]
- Continuously
- Monthly
- Quarterly
- Semi-annually
- Annually
- Biannually

Taken together, these survey responses suggest that proactive pentesting is widely viewed as an essential part of cybersecurity programs as well as a major business driver.

The next section analyzes findings from penetration tests conducted via Cobalt over the last decade. You’ll see right from the start that the perspectives shared here don’t always align with reality.

## Top Pentesting Findings

According to most survey respondents, this should be a fairly short section. More than 8 in 10 of them expressed confidence that their organization’s security posture meets all relevant regulatory requirements. The fact that this is not a short section but is rather filled with high-risk pentest findings suggests a widespread tendency for overconfidence.

![Figure 6: Confidence in regulatory requirements]
CONFIDENT IN REGULATORY REQUIREMENTS

Regardless of your view on whether compliance equals security or not, we can probably all agree that the feeling of being compliant or secure doesn’t mean you’ve actually achieved either state. In fact, that’s one of the main reasons why penetration tests exist. It’s better to expose security issues now than turn a blind eye until attackers exploit them later.

Cobalt pentesters follow specific methodologies depending on the type of test they’re performing. By default, that includes industry-standard vulnerabilities from the Open Web Application Security Project (OWASP), which includes different top 10 lists for web, API, mobile, AI/LLM, and cloud systems. The Open Source Security Testing Methodology Manual (OSSTMM) is used for pentests of internal and external networks. More details on each of our pentesting methodologies can be found on the Cobalt website.

Pentest findings shared with the customer include exploitation details, impact assessment, and proof of concept with steps to reproduce.

Every pentest we conducted uncovered at least one reportable finding[^1], but the median number was six. The majority of organizations had 10 or fewer findings. That said, over a quarter of pentests revealed more than that, and some resulted in a list of issues that stretched into the low hundreds. All sector and size groups showed this same overall distribution with only slight variation.

![Figure 7: Number of findings in each pentest]

We suspect the number of findings depicted here may strike some as low. It’s much lower than, for example, the number of issues typically identified with a vulnerability scanner. But keep in mind that pentests are often focused on a particular asset or group of assets rather than the entirety of enterprise infrastructure.

### Web applications and APIs

Furthermore, findings uncovered by vulnerability scanners and code analysis are more theoretical in nature. They’re weaknesses that, given the right circumstances (which usually aren’t accounted for), could be exploited.

Pentest findings, on the other hand, do account for relevant circumstances (e.g., accessibility and mitigating controls) and are proven to be exploitable by the pentester. The outcome is a smaller set of real risks.

> Pentest findings are grounded in human expertise, revealing how vulnerabilities can be actively exploited in real-world scenarios. Unlike scanner results, pentests go beyond the theoretical to uncover the full scope of exposures and highlight what truly poses risk to your organization.

As previously mentioned, pentests are specific to certain types of assets. This section presents the most prevalent findings associated with three popular pentest methodologies, starting with web applications (which include APIs and microservices).

Figure 8 shows that server misconfigurations are the most common type of finding. This category has a broad scope from OWASP, referring to improper implementation of security controls on a server that leaves it vulnerable to exploitation. This can result from default settings, unnecessary services, misconfigured permissions, or missing security patches.

![Figure 8: Most common web and API pentest findings in 2024 (all criticalities)]

Missing access control lands at number two, indicating that improper enforcement of authentication and authorization measures is a significant issue, allowing unauthorized users to access sensitive data or functionalities. Identified in just shy of 1 in 10 pentests, cross-site scripting rounds out the top three. Along with sensitive data exposure (8.1%) and authentication and session vulnerabilities (8%), this highlights persistent weaknesses in handling user inputs securely and protecting confidential information.

### Mobile applications

Top findings from mobile application pentests are revealed in Figure 9. Modern mobile apps are so tightly coupled with web services that it’s not surprising that the findings are similar. Security misconfigurations once again take the lead. and missing access control remains among the more common findings. Issues stemming from a lack of binary hardening in mobile apps allow attackers to reverse engineer and modify code to enable nefarious functions.

![Figure 9: Most common mobile application pentest findings in 2024 (all criticalities)]

Mobile security misconfiguration is a broad category that includes findings such as a lack of SSL pinning, no jailbreak or root detection, unnecessary software components, and having the clipboard enabled. Many of these exist because the business has deemed them an accepted risk.

The presence of server misconfiguration issues may seem out of place here, but part of mobile testing is checking the API connections between the application and the mobile device. In general, secure enclave architectures have done a great job of protecting mobile devices and apps from vulnerabilities in other apps. Vulnerabilities in connected SaaS components, however, can be exploited and used as gateways to wider access. In that sense, it’s not surprising that mobile pentest findings share similarities with application pentests above.

### AI and LLMs

AI is the driving force behind business and technology trends today. For a growing number of companies, remaining competitive means integrating AI into their workflows and products. These trends are reflected in responses from survey participants. Nearly all of them (98%) say their organizations are currently integrating genAI into their products and services.

These capabilities, of course, introduce new and unique threats that must be managed. The organizations we surveyed seem to understand this well. Securing genAI tops their list of concerns, ranking above known exploited vulnerabilities, insider threats, and nation-state attackers. About 80% say they’re increasing efforts to secure AI, and 66% are actively conducting regular security assessments (including pentesting) of their AI-powered solutions.

![Figure 10: A risky combo: Breakneck adoption and lagging security of genAI]

What is it about genAI threats that so many organizations find concerning? We asked survey participants that very question, and their responses ranged from technical and operational issues (e.g., data exposure and integration) to governance and ethical challenges. The breadth of the concerns expressed is indicative of the uncertainty surrounding the security and safety of AI and LLM applications.

![Figure 11: What concerns you most about AI/LLM-related threats for customer-facing applications?]
- DATA PRIVACY AND UNINTENDED EXPOSURE OF SENSITIVE DATA
- INSECURE INTEGRATION WITH EXISTING APPLICATIONS
- PROMPT INJECTION ATTACKS AND ADVERSARIAL MANIPULATION
- LACK OF VISIBILITY INTO AI-GENERATED OUTPUTS
- MODEL BIAS AND ETHICAL RISKS

Cobalt’s AI testing follows the OWASP Top 10 for LLM Applications, focusing on sensitive data exposure, insecure output handling, and injection attacks that could compromise model integrity. Our pentesters conduct dynamic testing to detect prompt injections and model-based DoS vulnerabilities, while also assessing LLM production services and plugins for unauthorized data exfiltration or excessive system access. This comprehensive approach ensures robust security in LLM environments, addressing risks traditional models may overlook.

The top five findings from AI and LLM pentests in the last year are highlighted in Figure 12. We’ve included common non-AI issues identified by these tests as well (in gray). This is a reminder that AI applications are still prone to the same old findings that affect any application. But we’ll highlight the AI and LLM findings here.

![Figure 12: Most common AI and LLM pentest findings in 2024 (all criticalities)]

The most prevalent LLM-specific findings concern insecure output handling, where improper validation of model-generated responses can lead to data leaks, injection attacks, or security misconfigurations. Prompt injection vulnerabilities follow closely, which could enable attackers to manipulate model inputs to bypass safeguards or alter system behavior.

AI is changing quickly, and so are the risks. OWASP understands this and updated the 2025 edition of the Top 10 for LLM and genAI to expand on DoS and other availability issues. The new category is called Unbounded Consumption, and includes threats like Denial of Wallet (DoW), which attackers can use to exploit the cost-per-use model of AI services.

Issues that open the LLM to DoS attacks come next, which means adversaries can overload or disrupt LLMs, impacting availability. Findings associated with sensitive information disclosure highlight the risk of LLMs inadvertently exposing confidential data due to improper access controls. Lastly, overreliance refers to the tendency for misinformation, miscommunication, legal issues, and security vulnerabilities due to incorrect or inappropriate content generated by LLMs.

These findings underscore the need for robust security measures, including input validation, response filtering, and strict access controls to mitigate emerging LLM-related threats.

Download Cobalt’s whitepaper _The Responsible AI Imperative: Why Secure AI Is the Only AI That Matters_ to explore AI risks, pentesting challenges and methodologies, and best practices for securing AI applications.

### Severity of findings

As you likely suspect, not all security issues uncovered during a pentest carry the same risk for the organization. That’s why we rate the severity of all findings on their likelihood of exploitation and the potential impact on technical and business operations.

The product of these two ratings derives each finding’s level of risk. A rating of five on both scales yields a critical risk (25). High-risk findings score from 16 to 24 and so on. A proportional breakdown of severity for all findings in our sample is portrayed in Figure 13. [^2]

![Figure 13: Severity rating of pentest findings and breakdown by severity]

Much of our analysis going forward will focus on findings with a severity rating of high or very high (four boxes in the upper right), which we’ll dub “serious.” That designation represents about 13% of all non-informational findings from pentests conducted over the 10 years of our data. We’ll now explore how that ratio varies across tests and organizations.

All types of pentests can identify serious security issues, but some tend to do so more than others. Case in point, about one-third (32%) of the findings uncovered during our AI and LLM pentests warrant a serious rating. The fact that organizations are integrating AI capabilities at breakneck speed, combined with the nascency of security practices for those capabilities, undoubtedly contributes to this (see Figure 10).

Which types of findings tend to be the most serious? Figure 14 gives the relative frequency for the top 10 most common vulnerability types among serious findings. If you’re looking to make big strides in reducing your risk exposure, these offer a great starting point. This blog post on top web applications vulns offers additional context on these findings.

![Figure 14: Most common vulnerability types among serious findings (2024)]

Let’s close out this discussion with a brief look at how serious findings vary among different types and sizes of organizations. We’ll start with size because there’s not much to show or say on that aspect. The prevalence of serious findings is virtually the same across all size tiers. So, there’s no evidence to conclude that SMBs or large corporations are less prone to risky issues.

The sectors in Figure 15 and other charts in the report use the North American Industry Classification System (NAICS). We’ve linked the first reference to each sector to the corresponding page on the NAICS website for those who want more detailed descriptions.

There is some evidence, however, that pentests are more likely to find serious issues in certain industries. Figure 15 reveals that the [Administrative Services](https://www.naics.com/naics-code-description/?code=561), [Transportation](https://www.naics.com/naics-code-description/?code=48), [Hospitality](https://www.naics.com/naics-code-description/?code=72), [Manufacturing](https://www.naics.com/naics-code-description/?code=31-33), and [Education](https://www.naics.com/naics-code-description/?code=61) sectors have the highest proportion of serious findings, but several others are right up there with them.

![Figure 15: Prevalence of serious findings by industry]

The [Entertainment](https://www.naics.com/naics-code-description/?code=71) industry (composed mainly of gaming, gambling companies, and video streaming companies) stands out with the lowest ratio. The [Financial Services](https://www.naics.com/naics-code-description/?code=52) and [Information Services](https://www.naics.com/naics-code-description/?code=51) sectors also show low rates, which suggests they manage issues well despite having high volumes of sensitive data and critical systems. Plus, stringent regulatory requirements may give them extra incentive to minimize risk exposures.

### Resolution of findings

With many types of tests, the hard part is in preparing for the exam. Once it’s done, you move on. Pentests are different in that the hard part comes after the exam results are posted. We’re talking, of course, about fixing or otherwise resolving security issues identified by the pentest. That’s where the real work begins.

There’s a lot vying for the attention of security teams these days, and it’s impossible to fix all the issues from all the things all the time. According to survey respondents, pentests rank high on the list of things that should get priority attention from security teams. It’s tied for second with known exploited vulnerabilities and right behind alerts from threat detection and response tooling.

Despite the consensus that pentests demand attention, our data reveals that less than half (48%) of all pentest findings actually get resolved. That ratio does improve to 69% among serious findings, indicating intent to prioritize issues that